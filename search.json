[{"path":"https://nateybear.github.io/metrics-in-r/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://nateybear.github.io/metrics-in-r/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://nateybear.github.io/metrics-in-r/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://nateybear.github.io/metrics-in-r/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://nateybear.github.io/metrics-in-r/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://nateybear.github.io/metrics-in-r/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/bootstrap.html","id":"the-idea-a-bit-of-magic","dir":"Articles > Art","previous_headings":"","what":"The Idea: A Bit of Magic","title":"Bootstrap and Quantile Regression","text":"first learn bootstrap, may seem little magical. seem get lot free, need resample data bunch times order get sampling distribution statistic like. Definition: Recall believe “true value” population-level statistic. , mean (unknown) number, \\(\\beta\\) coefficients true (unknown) numbers. uncertainty estimating \\(\\beta\\) comes fact finite sample entire population. imagine drawing many samples length \\(N\\) population, intuitively know get different values \\(\\beta\\) sample. distribution \\(\\beta\\)s called sampling distribution. distribution statistic due sampling variation. want emphasize two points, ’ll move onto coding.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/bootstrap.html","id":"the-sample-analogue-and-wlln","dir":"Articles > Art","previous_headings":"The Idea: A Bit of Magic","what":"The “Sample Analogue” and WLLN","title":"Bootstrap and Quantile Regression","text":"bootstrap something, get back bunch numbers. numbers random sample distribution! random sample sampling distribution \\(\\beta\\). “conduct inference” \\(\\beta\\)s, just need ask questions sample \\(\\beta\\)s ’re given. fundamentally different way statistical inference classical way saying \\(\\beta\\)s normally distributed distribution using critical values standard normal accept/reject hypothesis. law large numbers along continuous mapping theorem gives us lot power. basically tells us can take average value function \\(g\\) sample \\(\\beta\\)s, good estimate true value \\(g\\) entire population. Formally write \\[ \\frac{1}{B} \\sum_{=1}^B g(\\beta_i) \\overset{p}\\rightarrow g(\\beta) \\] also want point sample analogue technique intuitively applies situations. sample median \\(\\beta\\)s pretty good guess population median. 5%-95% interval sample \\(\\beta\\)s pretty good estimate 90% interval true value \\(\\beta\\). Let’s make concrete. Say bootstrapping OLS coefficients regression, want estimate “turning point” mage Problem Set 2. take \\(\\beta\\) samples construct \\[ \\theta_i \\equiv -\\beta_{mage}^/(2\\beta_{magesq}^) \\] now can think \\(\\theta_i\\) draws sampling distribution turning point. take mean \\(\\theta_i\\), estimate mean value turning point. take 5th 95th percentiles \\(\\theta_i\\), 90% confidence interval true value turning point. Conclusion: bootstrapping, generating random sample statistic finite amount data. magic resampling. emphasize generality, let expand idea statistic.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/bootstrap.html","id":"bootstrap-works-for-any-statistic","dir":"Articles > Art","previous_headings":"The Idea: A Bit of Magic","what":"Bootstrap Works for Any Statistic","title":"Bootstrap and Quantile Regression","text":"Defintion: statistic function takes sample data returns something. something general. can think statistic OLS coefficient (data , linear regression ), sample mean, sample variance. can also think bigger: nonparametric statistics, like kernel regression estimators, machine learning models… don’t return number, can return function, data structure, basically anything can program. truly doesn’t matter, can think sort thing takes data produces output, can use bootstrap quantify amount uncertainty output.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/bootstrap.html","id":"how-to-code-it","dir":"Articles > Art","previous_headings":"","what":"How to Code It","title":"Bootstrap and Quantile Regression","text":"example: want bootstrap median wage HTV dataset. Since bootstrapping computationally straightforward, ’s nothing stopping . just need loop:  overlayed normal curve output show median doesn’t look normal! might suggest better suited using boostrap answer statistical questions .","code":"library(haven) library(tidyverse)  # Read in the data data <- read_dta(system.file(\"HTV.DTA\", package = \"metrics.in.r\"))  wage <- data$wage  n <- length(wage)  # make a vector to hold the output median_samples <- numeric() for (i in 1:1000) {     wage_resample <- wage[sample(1:n, n, replace = TRUE)]     median_samples[i] <- median(wage_resample) }  # plot a histogram of the output hist(median_samples, prob = TRUE) curve(dnorm(x, mean(median_samples), sd(median_samples)), add = TRUE)"},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/bootstrap.html","id":"there-are-packages-for-that","dir":"Articles > Art","previous_headings":"How to Code It","what":"There are packages for that","title":"Bootstrap and Quantile Regression","text":"One package really like bootstrapping mosaic. add special syntax stats feels pretty intuitive. can read . equivalent code mosaic looks like : ’s another package learned mosaic called boot. function called boot works slightly differently. give data resample, function compute statistic. Documentation . look like : Notice doesn’t return numeric vector like mosaic DIY versions, instead “boot object” print summary bootstrap procedure.","code":"library(mosaic)  median_samples <- do(1000) * median(resample(wage)) library(boot)  boot(wage, function(data, i) median(data[i]), R = 1000) ##  ## ORDINARY NONPARAMETRIC BOOTSTRAP ##  ##  ## Call: ## boot(data = wage, statistic = function(data, i) median(data[i]),  ##     R = 1000) ##  ##  ## Bootstrap Statistics : ##     original     bias    std. error ## t1*  11.5429 0.08473248   0.2259398"},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/bootstrap.html","id":"enter-quantile-regression","dir":"Articles > Art","previous_headings":"","what":"Enter Quantile Regression","title":"Bootstrap and Quantile Regression","text":"talk quantile regression bootstrap article? quantile regression great example something much easier bootstrap classical statistics. Quantile regression can done R using quantreg package. written Roger Koenker, one fathers quantile regression. can create quantile regression model much like linear model R, appropriate function rq. also takes additional argument, tau, quantiles want estimate. Let’s create quantile regression model looks effects education, ability, experience wage two different quantiles:","code":"library(quantreg)  model <- rq(wage ~ educ + abil + exper, data = data, tau = c(0.25, 0.75))  model ## Call: ## rq(formula = wage ~ educ + abil + exper, tau = c(0.25, 0.75),  ##     data = data) ##  ## Coefficients: ##              tau= 0.25   tau= 0.75 ## (Intercept) -2.5251534 -12.2843990 ## educ         0.6169045   1.5504339 ## abil         0.5356258   0.7071306 ## exper        0.1940122   0.6063321 ##  ## Degrees of freedom: 1230 total; 1226 residual"},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/bootstrap.html","id":"its-a-matrix-whats-the-variance-of-a-matrix","dir":"Articles > Art","previous_headings":"Enter Quantile Regression","what":"It’s a matrix? What’s the variance of a matrix?","title":"Bootstrap and Quantile Regression","text":"coefficient estimates now stored matrix! OLS coefficients vector, ’ve added dimension tau. Random matrices kind complicated thing. ’s easier think \\(m\\times n\\) random matrix \\(m*n\\) length vector. way, covariance matrix quantile regression coefficients \\((m*n)\\times (m*n)\\)-dimensional matrix. Surely Roger Koenker, father quantile regression, realizes . Well, ’s great doesn’t provide vcov implementation box. least provides summary method models: Problem: package doesn’t compute covariances across quantiles. way us post-estimation like testnl lincom. Let’s step back discuss way forward.","code":"vcov(model) ## Error in UseMethod(\"vcov\"): no applicable method for 'vcov' applied to an object of class \"rqs\" summary(model) ##  ## Call: rq(formula = wage ~ educ + abil + exper, tau = c(0.25, 0.75),  ##     data = data) ##  ## tau: [1] 0.25 ##  ## Coefficients: ##             Value    Std. Error t value  Pr(>|t|) ## (Intercept) -2.52515  1.92828   -1.30954  0.19060 ## educ         0.61690  0.11196    5.50995  0.00000 ## abil         0.53563  0.08522    6.28542  0.00000 ## exper        0.19401  0.07378    2.62954  0.00866 ##  ## Call: rq(formula = wage ~ educ + abil + exper, tau = c(0.25, 0.75),  ##     data = data) ##  ## tau: [1] 0.75 ##  ## Coefficients: ##             Value     Std. Error t value   Pr(>|t|)  ## (Intercept) -12.28440   2.56243   -4.79405   0.00000 ## educ          1.55043   0.14868   10.42786   0.00000 ## abil          0.70713   0.12675    5.57891   0.00000 ## exper         0.60633   0.10479    5.78601   0.00000"},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/bootstrap.html","id":"matrix-gumming-up-the-machinery","dir":"Articles > Art","previous_headings":"","what":"Matrix Gumming up the Machinery","title":"Bootstrap and Quantile Regression","text":"fundamental problem coefficients matrix scenario none tools accounted . Sandwich tends flexible type model, quantile regressions messes dimensions one matrix multiplications: Mosaic also nice tools bootstrapping models, doesn’t quite work quantile regressions either. Compare linear model: quantile regression: ’s clear little inventive coding order make quantile regression work like linear regression ’re used .","code":"library(sandwich) vcovBS(model) ## Error in rval + sign[i] * cov(cf, use = use): non-conformable arrays mosaic_out <- do(1000) * lm(     wage ~ educ + abil + exper,      data = resample(data) ) confint(mosaic_out) ##        name       lower       upper level     method    estimate ## 1 Intercept -24.2248849 -10.1248815  0.95 percentile -16.6397660 ## 2      educ   1.2881430   2.1616274  0.95 percentile   1.7015644 ## 3      abil   0.2813780   0.7090569  0.95 percentile   0.4879376 ## 4     exper   0.4357194   0.8698818  0.95 percentile   0.6393264 ## 5     sigma   7.3391319   9.4515847  0.95 percentile   8.3210291 ## 6 r.squared   0.1278415   0.2039538  0.95 percentile   0.1625965 ## 7         F  59.9025740 104.7038767  0.95 percentile  79.3497685 mosaic_out <- do(1000) * rq(     wage ~ educ + abil + exper,     data = resample(data),     tau = c(0.25, 0.75) ) confint(mosaic_out) ## [1] name   lower  upper  level  method ## <0 rows> (or 0-length row.names)"},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/bootstrap.html","id":"solution-1-change-what-youre-bootstrapping","dir":"Articles > Art","previous_headings":"","what":"Solution 1: Change What You’re bootstrapping","title":"Bootstrap and Quantile Regression","text":"one hand, ’ll probably interested specific function \\(\\beta\\)s, can change ’re bootstrapping. makes amenable using mosaic conduct inference. example, might interested difference returns experience 75th percentile earners opposed 25th. words, care value \\(\\beta_{exper(0.75)} - \\beta_{exper(0.25)}\\). just bootstrap : output tells us expected returns experience 20 60 cents higher higher earners lower earners, HAEF. solution pretty straightforward, long know priori function \\(\\beta\\)s ’re interested .","code":"diff_pe_exper <- function(data) {     model <- rq(wage ~ abil + exper + educ, data = data, tau = c(0.25, 0.75))     pe_exper_0.25 <- coef(model)[\"exper\", \"tau= 0.25\"]     pe_exper_0.75 <- coef(model)[\"exper\", \"tau= 0.75\"]     return(pe_exper_0.75 - pe_exper_0.25) }  diff_pe_expers <- do(1000) * diff_pe_exper(resample(data))  confint(diff_pe_expers) ##            name     lower     upper level     method estimate ## 1 diff_pe_exper 0.2274937 0.5872442  0.95 percentile  0.41232"},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/bootstrap.html","id":"solution-2-implement-a-new-vcov-function","dir":"Articles > Art","previous_headings":"","what":"Solution 2: Implement a new vcov function","title":"Bootstrap and Quantile Regression","text":"’re big fan test, lincom, friends, solution won’t work . ’re still lacking way get variance matrix \\(\\beta\\)s. ’s help . load metrics..r package, implement new default methods get covariance matrix quantile regression model. ’s super fancy, just converts matrix coefficients vector coefficients, like : run vcov model, names covariance matrix. Use R parameter change number bootstrap iterations: Putting together: machinery place, can use lincom command run comparison , returns experience high vs. low earners:","code":"library(metrics.in.r)  normalized_coef(model) ## (Intercept)[0.25]        educ[0.25]        abil[0.25]       exper[0.25]  ##        -2.5251534         0.6169045         0.5356258         0.1940122  ## (Intercept)[0.75]        educ[0.75]        abil[0.75]       exper[0.75]  ##       -12.2843990         1.5504339         0.7071306         0.6063321 vcov(model, R = 100) ##                   (Intercept)[0.25]    educ[0.25]    abil[0.25]   exper[0.25] ## (Intercept)[0.25]        3.05964648 -0.1596113099  0.0277548590 -0.0920822482 ## educ[0.25]              -0.15961131  0.0101242832 -0.0031352182  0.0031663337 ## abil[0.25]               0.02775486 -0.0031352182  0.0068248683  0.0003682102 ## exper[0.25]             -0.09208225  0.0031663337  0.0003682102  0.0044977073 ## (Intercept)[0.75]        1.30028026 -0.0833079185  0.0338220738 -0.0319297662 ## educ[0.75]              -0.08926323  0.0064959747 -0.0035615565  0.0014083107 ## abil[0.75]               0.03212956 -0.0027951201  0.0056278899 -0.0003267764 ## exper[0.75]             -0.01847228  0.0005239467  0.0004108433  0.0012921464 ##                   (Intercept)[0.75]   educ[0.75]    abil[0.75]   exper[0.75] ## (Intercept)[0.25]        1.30028026 -0.089263233  0.0321295590 -0.0184722803 ## educ[0.25]              -0.08330792  0.006495975 -0.0027951201  0.0005239467 ## abil[0.25]               0.03382207 -0.003561557  0.0056278899  0.0004108433 ## exper[0.25]             -0.03192977  0.001408311 -0.0003267764  0.0012921464 ## (Intercept)[0.75]        6.28821555 -0.402361577  0.1357919878 -0.1457707408 ## educ[0.75]              -0.40236158  0.029213381 -0.0133234311  0.0058479459 ## abil[0.75]               0.13579199 -0.013323431  0.0179562249  0.0008463202 ## exper[0.75]             -0.14577074  0.005847946  0.0008463202  0.0073146552 lincom(model, `exper[0.75]` - `exper[0.25]`) ## # A tibble: 1 × 7 ##   Expression    Estimate `Std. Error` `t-Value` `Pr(>|t|)` `CI Lower` `CI Upper` ##   <chr>            <dbl>        <dbl>     <dbl>      <dbl>      <dbl>      <dbl> ## 1 `exper[0.75]…    0.412       0.0923      4.47 0.00000859      0.593      0.231"},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/bootstrap.html","id":"conclusion-and-comparison-of-solutions","dir":"Articles > Art","previous_headings":"","what":"Conclusion and Comparison of Solutions","title":"Bootstrap and Quantile Regression","text":"First, note solution 2 normal-based boostrap approach. get covariance matrix parameters bootstrap, use normal-based asymptotics test lincom commands. Solution 1 completely non-parametric, making distributional assumption getting bootstrap samples statistic. ways solution 2 feels little heavier, change “machinery” order account weirdness quantile regression models. hand, now “just works” just like linear models. Solution 1 requires little finagling tailoring get code right, way prone user error. end, illustrates trade-computer programming. ’s certainly attractive design system complex interacting parts, end result user extremely simple intuitive code—think Solution 2, tidyverse. lot burden designers systems, example something like quantile regression inevitably comes along turns pain point users. falls designers create way quantile regression fit tidy system, can involve difficult, sometimes painful trade-offs code gets written. approach “libertarian” designer leave user’s control. like Solution 1, user understand shape quantile regression model way can use mosaic . say ’s “bulletproof” design philosophy, ’re also probably giving users enough rope hang . real world black white, ’s hard neatly categorize R package fitting one buckets. However, think important distinction make, gain experience programmer helps start framing decisions package creators make understand trade-offs weighing. Happy Coding!","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/intro-lm.html","id":"a-data-frame-for-everyone","dir":"Articles > Art","previous_headings":"","what":"A data frame for everyone","title":"Intro: An lm for Everyone","text":"R fundamentally different Stata can work one dataset time. Stata, use command loads single dataset memory. R, create data frame save variable. can many data frames loaded want. haven package R can used load Stata .dta files. example . Note system.file() command locates .dta file included package. code loads HTV.DTA file included package saves variable named htv. can see output htv “tibble” another name data frame. See Chapter 5 R Data Science information transform data frame create new variables, summarize datasets, etc.","code":"library(haven) htv <- read_dta(system.file(\"HTV.DTA\", package = \"metrics.in.r\")) htv #> # A tibble: 1,230 × 23 #>     wage   abil  educ    ne    nc  west south exper motheduc fatheduc brkhme14 #>    <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>    <dbl> #>  1 12.0   5.03     15     0     0     1     0     9       12       12        0 #>  2  8.91  2.04     13     1     0     0     0     8       12       10        1 #>  3 15.5   2.48     15     1     0     0     0    11       12       16        0 #>  4 13.3   3.61     15     1     0     0     0     6       12       12        0 #>  5 11.1   2.64     13     1     0     0     0    15       12       15        1 #>  6 17.5   3.47     18     1     0     0     0     8       12       12        0 #>  7 21.1  -1.76     13     1     0     0     0    13       13       12        0 #>  8 11.7  -0.134    12     0     0     0     1    14       12       12        1 #>  9 17.0   2.07     13     1     0     0     0     9       10       12        1 #> 10 11.5  -0.338    12     1     0     0     0     9       14       12        0 #> # ℹ 1,220 more rows #> # ℹ 12 more variables: sibs <dbl>, urban <dbl>, ne18 <dbl>, nc18 <dbl>, #> #   south18 <dbl>, west18 <dbl>, urban18 <dbl>, tuit17 <dbl>, tuit18 <dbl>, #> #   lwage <dbl>, expersq <dbl>, ctuit <dbl>"},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/intro-lm.html","id":"a-formula-for-everyone","dir":"Articles > Art","previous_headings":"","what":"A formula for everyone","title":"Intro: An lm for Everyone","text":"get running regressions, ’s worth talking little bit describe regressions R. special object called formula symbolic description equation want estimate. simply put outcome variable left-hand side explanatory variables right-hand side, like : saying want estimate wage function ability, education, mother’s education. ’s symbolic description objects wage, abil, educ, motheduc aren’t actually defined! , get error : without elaborating much, just want show formulas “special” objects R. means “special” rules formulas need know: want include product two variables formula, use : like : wage ~ abil:educ. regresses wage product ability education. can use * get main effects well interactions, wage ~ abil * educ wage ~ abil + educ + abil:educ. can estimate model without intercept adding -1 end formula, wage ~ educ + abil - 1 regresses wage education ability intercept. can use functions inside formula, .e. log(wage) ~ abil + educ regresses log wage education ability. HOWEVER, ^ special meaning formulas, wage ~ educ^2 regressing wage education squared! special function () escape special meaning formulas. write wage ~ (educ^2) regress wage squared education. weird gotcha, generally prefer generate new variable, .e. htv |> mutate(educ_sq = educ^2) using wage ~ educ_sq formula. See “data frames” note information generating new variables. rules can read typing ?formula R console, “need know” rules, opinion.","code":"wage ~ abil + educ + motheduc #> wage ~ abil + educ + motheduc wage #> Error in eval(expr, envir, enclos): object 'wage' not found"},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/intro-lm.html","id":"an-lm-for-everyone","dir":"Articles > Art","previous_headings":"","what":"An lm for Everyone","title":"Intro: An lm for Everyone","text":"Now know load data frame write formula, can create regression model. primary function lm function, stands “linear model.” Linear models R require formula data frame input. Let’s see example looks like: see estimates \\(\\beta_i\\)s regression model \\[ E(\\text{wage}\\mid \\text{educ}, \\text{abil}) = \\beta_1 + \\beta_2\\text{educ} + \\beta_3\\text{abil} + \\beta_4\\text{educ}*\\text{abil} \\] ’s lot information can get linear model, however. Let’s store model variable see can : demonstrates model variable stores information related fitting linear model. names model information stores. instance, can see coefficient estimates writing can also get coefficients model using coef() function like : programming best practice known roughly “hiding implementation details.” model$coefficients call want access coefficients, general. fact, linear models avoid using properties names(model) directly, can. ?  properties names(model) represent internal structure linear model object. run names(model) give idea internal things might want store estimating linear model. However, external public ways interacting linear models meant us, users linear models. coef one example. fact, type ?coef R console read first sentence: coef generic function extracts model coefficients objects returned modeling functions. idea generics fundamental programming concept. coef function just linear models, many, many types models! Generalized linear models, local linear models, LASSO ridge models implement function. type model can choose implement coef function using internal structure, users don’t know care model chooses . just need call coef function. simplifies lives reducing number functions amount detail learn.","code":"lm(wage ~ educ * abil, data = htv) #>  #> Call: #> lm(formula = wage ~ educ * abil, data = htv) #>  #> Coefficients: #> (Intercept)         educ         abil    educ:abil   #>    -0.65484      0.98368     -0.40005      0.06939 model <- lm(wage ~ educ * abil, data = htv) names(model) #>  [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"          #>  [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"   #>  [9] \"xlevels\"       \"call\"          \"terms\"         \"model\" model$coefficients #> (Intercept)        educ        abil   educ:abil  #> -0.65483870  0.98368161 -0.40005124  0.06938703 coef(model) #> (Intercept)        educ        abil   educ:abil  #> -0.65483870  0.98368161 -0.40005124  0.06938703"},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/intro-lm.html","id":"within-the-lm","dir":"Articles > Art","previous_headings":"An lm for Everyone","what":"Within the lm","title":"Intro: An lm for Everyone","text":"non-exhaustive list generic functions can use linear models. summary table coefficients standard errors (assuming homoskedasticity!), F-statistic, R-squared, residual MSE: vector fitted values \\(\\widehat{\\text{wage}}\\) residuals \\(\\hat{u}\\), respectively: covariance matrix \\(\\beta_i\\)s, assuming homoskedasticity:","code":"summary(model) #>  #> Call: #> lm(formula = wage ~ educ * abil, data = htv) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -17.943  -4.602  -1.184   2.420  69.450  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept) -0.65484    1.97210  -0.332    0.740     #> educ         0.98368    0.16900   5.821 7.48e-09 *** #> abil        -0.40005    0.56506  -0.708    0.479     #> educ:abil    0.06939    0.04565   1.520    0.129     #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 8.438 on 1226 degrees of freedom #> Multiple R-squared:  0.1388, Adjusted R-squared:  0.1367  #> F-statistic: 65.88 on 3 and 1226 DF,  p-value: < 2.2e-16 fitted(model) #>        1        2        3        4        5        6        7        8  #> 17.32193 13.15564 15.68683 16.41302 13.45652 20.00085 11.24712 11.09155  #>        9       10       11       12       13       14       15       16  #> 13.17334 11.00293 11.74663 12.62569 19.47078 12.68040 20.02992 16.59600  #>       17       18       19       20  #> 17.54809 16.83575 15.64953 22.10532  #>  [ reached getOption(\"max.print\") -- omitted 1210 entries ] #> attr(,\"label\") #> [1] \"hourly wage, 1991\" #> attr(,\"format.stata\") #> [1] \"%9.0g\" resid(model) #>           1           2           3           4           5           6  #>  -5.3026990  -4.2429855  -0.1724920  -3.0796881  -2.3864056  -2.5183286  #>           7           8           9          10          11          12  #>   9.8499222   0.5755521   3.7877886   0.5355364   3.0681884   8.0734791  #>          13          14          15          16          17          18  #>   9.2129169  -0.1804047  15.8412321   6.8072210  -0.9066400  -0.7906550  #>          19          20  #>  -3.6303015 -13.5704727  #>  [ reached getOption(\"max.print\") -- omitted 1210 entries ] #> attr(,\"label\") #> [1] \"hourly wage, 1991\" #> attr(,\"format.stata\") #> [1] \"%9.0g\" vcov(model) #>             (Intercept)         educ        abil    educ:abil #> (Intercept)  3.88918247 -0.328879090 -0.57247356  0.056087334 #> educ        -0.32887909  0.028561667  0.05072765 -0.005085001 #> abil        -0.57247356  0.050727650  0.31928964 -0.025023818 #> educ:abil    0.05608733 -0.005085001 -0.02502382  0.002083647"},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/intro-lm.html","id":"postscript-factors-and-xpd","dir":"Articles > Art","previous_headings":"","what":"Postscript: Factors and xpd","title":"Intro: An lm for Everyone","text":"Two points ’re hungry . First, handling non-numeric columns much nicer R Stata. general, just works. Typically, categorical variable think estimating linear model including categorical variable estimating set dummy variables equal one zero “level” categorical variable. example HTV dataset region individual lives : code selecting four columns picking 10 random rows. ’s just demonstrate four columns take mutually exclusive values one zero. can convert one column categorical value region. One way use case_when() function: Now create linear model using region variable, R create dummies us! Hence, whereas Stata need concerned whether one categorical column set dummy variables, R programming language smart enough convert two relatively easily. information categorical variables R, see chapter 15 R Data Science . Second, find writing really big formulas, might consider tool fixest package called xpd(). performs several different types “formula expansion” make formulas little concise. bunch columns numbered sequentially, : quantifiable pattern formula, can use something called regular expression. can read regular expressions Chapter 14 R Data Science . ’s example gets columns HTV end “educ”: Happy coding!","code":"library(tidyverse) htv |>    select(nc18, ne18, south18, west18) |>    sample_n(10) #> # A tibble: 10 × 4 #>     nc18  ne18 south18 west18 #>    <dbl> <dbl>   <dbl>  <dbl> #>  1     0     0       1      0 #>  2     1     0       0      0 #>  3     0     1       0      0 #>  4     1     0       0      0 #>  5     0     0       1      0 #>  6     1     0       0      0 #>  7     1     0       0      0 #>  8     1     0       0      0 #>  9     0     1       0      0 #> 10     0     0       0      1 htv <- htv |>   mutate(region = case_when(     ne18 == 1    ~ \"Northeast\",     nc18 == 1    ~ \"North-Central\",     west18 == 1  ~ \"West\",     south18 == 1 ~ \"South\"   ))  htv |> select(region) |> sample_n(10) #> # A tibble: 10 × 1 #>    region        #>    <chr>         #>  1 Northeast     #>  2 Northeast     #>  3 West          #>  4 Northeast     #>  5 North-Central #>  6 West          #>  7 West          #>  8 North-Central #>  9 North-Central #> 10 North-Central lm(wage ~ region, data = htv) #>  #> Call: #> lm(formula = wage ~ region, data = htv) #>  #> Coefficients: #>     (Intercept)  regionNortheast      regionSouth       regionWest   #>         12.7275           2.6015          -0.5605           0.5629 library(fixest) xpd(y ~ x.[1:20]) #> y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + x11 +  #>     x12 + x13 + x14 + x15 + x16 + x17 + x18 + x19 + x20 xpd(wage ~ ..(\"^.*educ$\"), data = htv) #> wage ~ educ + motheduc + fatheduc"},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/panel.html","id":"idea","dir":"Articles > Art","previous_headings":"","what":"Idea","title":"Panel Data and Fixed Effects Regression","text":"Fixed effects regression one things don’t necessarily need another package . standard linear model tools, either R Stata. Hence, set bar pretty high package use fixed effect regression package. contribute lot productivity, otherwise bother learning ?","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/panel.html","id":"rolling-it-ourselves","dir":"Articles > Art","previous_headings":"","what":"Rolling it ourselves","title":"Panel Data and Fixed Effects Regression","text":"Remember class “within” fixed effects estimator running OLS dummy variables group id. can definitely . data ’ll use example wage panel data problem set. ’ll filter couple years. group id variable nr year ID year. Let’s estimate two-way fixed effects model \\[ lwage_{} = \\beta_1 + \\beta_2 union_{} + \\delta_i + \\delta_t + u_{} \\] words, care returns union membership percentage terms, controlling unobserved heterogeneity across years individuals. Categorical variables R called “factors.” put regression formula, R create dummy variables actual regression. Hence, let’s convert year nr factors formula estimate model via OLS: ’s lot output! can see, R reports coefficient estimate every dummy variable. ’ll probably want filter results variables care , ’ll . terms computing standard errors, almost always cluster standard errors individual level. Remember, assumption unobservable component unique person determines wage. assumption true, residuals necessarily correlated within individuals, must compute standard errors robust clustered correlation. R using vcovCL function sandwich: Now can report coefficients using coeftest done past. ’ll use broom package filter fixed effect estimates.","code":"library(tidyverse) library(haven) data <-     read_dta(system.file(\"wagepan.dta\", package = \"metrics.in.r\")) %>%     filter(year < 1983) (model <- lm(lwage ~ union + as_factor(nr) + as_factor(year), data = data)) ##  ## Call: ## lm(formula = lwage ~ union + as_factor(nr) + as_factor(year),  ##     data = data) ##  ## Coefficients: ##         (Intercept)                union      as_factor(nr)17   ##           1.3266008            0.1181125            0.1588673   ##     as_factor(nr)18      as_factor(nr)45     as_factor(nr)110   ##           0.2020454            0.1085325            0.4930897   ##    as_factor(nr)120     as_factor(nr)126     as_factor(nr)150   ##          -0.4121125            0.5466180           -0.2345779   ##    as_factor(nr)162     as_factor(nr)166     as_factor(nr)189   ##          -0.5460605           -0.4402726           -0.2809320   ##    as_factor(nr)193     as_factor(nr)209     as_factor(nr)212   ##           0.5350933            0.1282157            0.5110860   ##    as_factor(nr)218     as_factor(nr)243     as_factor(nr)259   ##           0.6580525            0.2204271            0.5358792   ##    as_factor(nr)260     as_factor(nr)309     as_factor(nr)351   ##           0.2863690            0.6847195            0.0749453   ##    as_factor(nr)353     as_factor(nr)383     as_factor(nr)408   ##           0.3106510            0.0982151            0.2486188   ##    as_factor(nr)424     as_factor(nr)464     as_factor(nr)483   ##           0.8659802           -0.4005279            0.2741420   ##    as_factor(nr)556     as_factor(nr)560     as_factor(nr)569   ##           0.6477222            0.0687833           -0.5581998   ##    as_factor(nr)583     as_factor(nr)647     as_factor(nr)658   ##           0.2845939           -0.0685340            0.2440167   ##    as_factor(nr)684     as_factor(nr)711     as_factor(nr)729   ##           1.0114142            0.0040234            0.8119867   ##    as_factor(nr)731     as_factor(nr)732     as_factor(nr)793   ##          -0.0497423            0.1089600            0.1494168   ##    as_factor(nr)797     as_factor(nr)800     as_factor(nr)813   ##           0.1684761            0.0246981           -0.5291300   ##    as_factor(nr)823     as_factor(nr)827     as_factor(nr)847   ##          -1.0594719           -0.2008313            0.1615324   ##    as_factor(nr)851     as_factor(nr)863     as_factor(nr)873   ##           0.4742646            0.1418878           -0.7443141   ##    as_factor(nr)891     as_factor(nr)908     as_factor(nr)910   ##           0.6617605           -0.9901529            0.2545301   ##    as_factor(nr)916     as_factor(nr)919     as_factor(nr)922   ##          -0.0247005           -0.0563176            0.5330584   ##    as_factor(nr)924     as_factor(nr)925     as_factor(nr)944   ##          -0.5603942            0.7388367           -0.4893991   ##    as_factor(nr)945     as_factor(nr)947     as_factor(nr)955   ##          -0.2056538            0.7894674            0.4688771   ##    as_factor(nr)965     as_factor(nr)996    as_factor(nr)1007   ##           0.0011922            0.0024493            0.1569972   ##   as_factor(nr)1054    as_factor(nr)1064    as_factor(nr)1081   ##          -0.1986985            0.5142225           -0.1308018   ##   as_factor(nr)1085    as_factor(nr)1091    as_factor(nr)1094   ##           0.1031126           -0.3927281            0.0006299   ##   as_factor(nr)1096    as_factor(nr)1098    as_factor(nr)1102   ##          -0.2450096            0.7203420            0.1591198   ##   as_factor(nr)1107    as_factor(nr)1142    as_factor(nr)1156   ##           0.1643931            0.2420108           -0.1146136   ##   as_factor(nr)1180    as_factor(nr)1190    as_factor(nr)1204   ##           0.2527814           -0.0646183            0.2655009   ##   as_factor(nr)1249    as_factor(nr)1272    as_factor(nr)1311   ##           0.0844531            0.3144074           -0.1595409   ##   as_factor(nr)1316    as_factor(nr)1318    as_factor(nr)1345   ##           0.2778284           -0.1365694           -0.4484422   ##   as_factor(nr)1397    as_factor(nr)1434    as_factor(nr)1492   ##           0.0959715           -0.6605361            0.0934701   ##   as_factor(nr)1496    as_factor(nr)1506    as_factor(nr)1515   ##          -0.7466057            0.0725290           -0.2513917   ##   as_factor(nr)1520    as_factor(nr)1528    as_factor(nr)1554   ##          -0.1445889           -0.3049101           -0.1505543   ##   as_factor(nr)1575    as_factor(nr)1576    as_factor(nr)1628   ##           0.2733155           -0.0141681           -0.1800837   ##   as_factor(nr)1641    as_factor(nr)1644    as_factor(nr)1653   ##           0.7133776           -0.2519397           -0.3808045   ##   as_factor(nr)1654    as_factor(nr)1721    as_factor(nr)1742   ##           0.1314616            0.4504153            0.1680601   ##   as_factor(nr)1744    as_factor(nr)1763    as_factor(nr)1777   ##           0.1545325           -0.5249411           -0.2199798   ##   as_factor(nr)1843    as_factor(nr)1891    as_factor(nr)1895   ##           0.9471332           -0.4396996            0.1992381   ##   as_factor(nr)1899    as_factor(nr)1925    as_factor(nr)1930   ##          -0.0689627           -0.0209432           -0.3039736   ##   as_factor(nr)1961    as_factor(nr)1963    as_factor(nr)1979   ##           0.2004823            0.2175404            0.4192028   ##   as_factor(nr)1988    as_factor(nr)2000    as_factor(nr)2014   ##          -0.3547352            0.3390797            0.4306733   ##   as_factor(nr)2025    as_factor(nr)2038    as_factor(nr)2075   ##          -0.0088173           -0.3322481            0.3358691   ##   as_factor(nr)2101    as_factor(nr)2106    as_factor(nr)2107   ##           0.7448600            0.1274726           -0.0777436   ##   as_factor(nr)2108    as_factor(nr)2147    as_factor(nr)2157   ##           0.3293251           -1.4220602           -0.3080365   ##   as_factor(nr)2163    as_factor(nr)2173    as_factor(nr)2180   ##           0.6401244           -0.1349283           -0.1263657   ##   as_factor(nr)2183    as_factor(nr)2216    as_factor(nr)2220   ##          -0.0503839            0.1857614            0.3705435   ##   as_factor(nr)2227    as_factor(nr)2264    as_factor(nr)2306   ##          -0.1358223           -0.3091959           -0.6756233   ##   as_factor(nr)2312    as_factor(nr)2314    as_factor(nr)2329   ##           0.3355878            0.5290060            0.3244606   ##   as_factor(nr)2335    as_factor(nr)2341    as_factor(nr)2351   ##           0.0383447           -0.3232691           -0.3374433   ##   as_factor(nr)2386    as_factor(nr)2401    as_factor(nr)2413   ##          -0.7008390           -0.1342346            0.6445750   ##   as_factor(nr)2421    as_factor(nr)2445    as_factor(nr)2451   ##          -0.1786544           -0.0166565            0.2330834   ##   as_factor(nr)2494    as_factor(nr)2508    as_factor(nr)2535   ##          -0.7329064            0.4873586            0.1781931   ##   as_factor(nr)2540    as_factor(nr)2685    as_factor(nr)2711   ##          -0.3678554            0.4867136           -0.3197433   ##   as_factor(nr)2718    as_factor(nr)2721    as_factor(nr)2733   ##           0.6427425            0.0711279           -0.5114629   ##   as_factor(nr)2741    as_factor(nr)2745    as_factor(nr)2751   ##          -0.0656126            0.3165448            0.1089606   ##   as_factor(nr)2774    as_factor(nr)2801    as_factor(nr)2813   ##           0.7161539           -0.2499014           -0.2545656   ##   as_factor(nr)2833    as_factor(nr)2839    as_factor(nr)2842   ##           0.4127922            0.2038677            0.2398360   ##   as_factor(nr)2866    as_factor(nr)2868    as_factor(nr)2874   ##           0.1589736            0.4256432           -0.6921180   ##   as_factor(nr)2916    as_factor(nr)2951    as_factor(nr)2980   ##           0.1074157           -0.2764584            0.0331924   ##   as_factor(nr)2994    as_factor(nr)2997    as_factor(nr)3017   ##           0.0254400            0.2189687            0.1251911   ##   as_factor(nr)3037    as_factor(nr)3059    as_factor(nr)3062   ##           0.5988740            0.2389050            0.7489376   ##   as_factor(nr)3100    as_factor(nr)3102    as_factor(nr)3127   ##          -0.0332785           -0.7166815           -1.0250521   ##   as_factor(nr)3136    as_factor(nr)3137    as_factor(nr)3138   ##           0.2869289            0.4581664            0.2596971   ##   as_factor(nr)3140    as_factor(nr)3193    as_factor(nr)3196   ##           0.4143431            0.0051748            0.3669188   ##   as_factor(nr)3200    as_factor(nr)3202    as_factor(nr)3207   ##           0.1586095            0.2291555            0.1892850   ##   as_factor(nr)3208    as_factor(nr)3210    as_factor(nr)3215   ##           0.3125633            0.1541200           -0.0896639   ##   as_factor(nr)3219    as_factor(nr)3226    as_factor(nr)3235   ##          -0.3633334           -0.3335658           -0.1901436   ##   as_factor(nr)3239    as_factor(nr)3271    as_factor(nr)3275   ##          -0.6941492           -0.0585147           -0.1518026   ##   as_factor(nr)3282    as_factor(nr)3289    as_factor(nr)3290   ##           0.0018243           -0.1431946           -0.0725325   ##   as_factor(nr)3307    as_factor(nr)3333    as_factor(nr)3353   ##           0.7359895           -0.8625462           -0.4078738   ##   as_factor(nr)3380    as_factor(nr)3381    as_factor(nr)3389   ##           0.0537697            0.0717494            0.1657350   ##   as_factor(nr)3394    as_factor(nr)3401    as_factor(nr)3414   ##           0.5586050           -0.2521901            0.4222398   ##   as_factor(nr)3420    as_factor(nr)3440    as_factor(nr)3461   ##           0.0271526           -1.2838070            0.2180308   ##   as_factor(nr)3468    as_factor(nr)3482    as_factor(nr)3495   ##           0.0166458            0.6722500            0.0808619   ##   as_factor(nr)3503    as_factor(nr)3525    as_factor(nr)3526   ##           0.5833753            0.0781587            0.2117918   ##   as_factor(nr)3538    as_factor(nr)3563    as_factor(nr)3575   ##           0.5578160            0.1964154            0.5930825   ##   as_factor(nr)3580    as_factor(nr)3581    as_factor(nr)3589   ##           0.0787277           -0.2308375           -0.4741645   ##   as_factor(nr)3591    as_factor(nr)3598    as_factor(nr)3602   ##           0.1519407            0.4057427            0.6102853   ##   as_factor(nr)3607    as_factor(nr)3621    as_factor(nr)3628   ##          -1.0411348            0.1111698            0.5311493   ##   as_factor(nr)3653    as_factor(nr)3706    as_factor(nr)3707   ##           0.4608529            0.2360062           -0.5906132   ##   as_factor(nr)3708    as_factor(nr)3743    as_factor(nr)3777   ##           0.2191805            0.1389024            0.4747418   ##   as_factor(nr)3831    as_factor(nr)3844    as_factor(nr)3847   ##          -0.1015208            0.0416051            0.7525291   ##   as_factor(nr)3848    as_factor(nr)3882    as_factor(nr)3937   ##           0.4888822           -0.7672207           -0.0710730   ##   as_factor(nr)4000    as_factor(nr)4004    as_factor(nr)4025   ##           0.2527725            0.6296114           -0.2607890   ##   as_factor(nr)4032    as_factor(nr)4046    as_factor(nr)4088   ##          -0.3283376            0.0409790            0.8845383   ##   as_factor(nr)4091    as_factor(nr)4122    as_factor(nr)4127   ##           1.0121476            0.4747729           -0.0337868   ##   as_factor(nr)4128    as_factor(nr)4159    as_factor(nr)4204   ##          -0.4703832            0.4559191           -0.0946723   ##   as_factor(nr)4229    as_factor(nr)4258    as_factor(nr)4261   ##           0.0579366            0.5815351            0.4183856   ##   as_factor(nr)4264    as_factor(nr)4278    as_factor(nr)4297   ##          -0.2256458            0.3754312            0.4935033   ##   as_factor(nr)4302    as_factor(nr)4321    as_factor(nr)4328   ##          -0.3179859            0.1724987            0.0384778   ##   as_factor(nr)4332    as_factor(nr)4335    as_factor(nr)4357   ##          -0.9461914            0.1431209            0.3664675   ##   as_factor(nr)4365    as_factor(nr)4380    as_factor(nr)4394   ##          -0.9217202            0.3694399            0.4465017   ##   as_factor(nr)4510    as_factor(nr)4559    as_factor(nr)4563   ##           0.0640553           -0.0683127           -0.4918190   ##   as_factor(nr)4569    as_factor(nr)4603    as_factor(nr)4607   ##           0.6114778            0.4868630           -0.4827456   ##   as_factor(nr)4633    as_factor(nr)4676    as_factor(nr)4701   ##           0.1175835           -0.5715178            0.3091466   ##   as_factor(nr)4716    as_factor(nr)4720    as_factor(nr)4759   ##          -0.3159763            0.7021370            0.1199122   ##   as_factor(nr)4791    as_factor(nr)4811    as_factor(nr)4828   ##           0.2497200           -0.6078364           -0.0345333   ##   as_factor(nr)4857    as_factor(nr)4858    as_factor(nr)4859   ##          -0.4686019            0.2787164           -0.2965494   ##   as_factor(nr)4866    as_factor(nr)4881    as_factor(nr)4884   ##           0.2704070           -0.0484928            0.1306036   ##   as_factor(nr)4888    as_factor(nr)4901    as_factor(nr)4917   ##          -0.0729494           -0.4033223           -0.3886961   ##   as_factor(nr)4926    as_factor(nr)4982    as_factor(nr)5017   ##           0.0838707           -0.3130062            0.6689182   ##   as_factor(nr)5033    as_factor(nr)5048    as_factor(nr)5122   ##           0.7467193           -0.4758237            0.1132699   ##   as_factor(nr)5141    as_factor(nr)5147    as_factor(nr)5158   ##           0.5984766            0.6499833            0.3148903   ##   as_factor(nr)5221    as_factor(nr)5223    as_factor(nr)5227   ##           0.0061269            0.3485008            0.1359778   ##   as_factor(nr)5248    as_factor(nr)5252    as_factor(nr)5263   ##          -0.0064682           -0.3008864            0.2013024   ##   as_factor(nr)5274    as_factor(nr)5335    as_factor(nr)5345   ##           0.6845062            0.2477231           -0.2279034   ##   as_factor(nr)5359    as_factor(nr)5368    as_factor(nr)5377   ##          -0.6833245           -0.3685628            0.1730136   ##   as_factor(nr)5390    as_factor(nr)5419    as_factor(nr)5435   ##           0.0543443           -0.6859831           -0.2344141   ##   as_factor(nr)5437    as_factor(nr)5497    as_factor(nr)5525   ##           0.0170750            0.0234595           -0.1783761   ##   as_factor(nr)5529    as_factor(nr)5531    as_factor(nr)5579   ##           0.0172448            0.1457726           -0.0699605   ##   as_factor(nr)5588    as_factor(nr)5599    as_factor(nr)5650   ##           0.2630069            0.3407023           -0.1208191   ##   as_factor(nr)5660    as_factor(nr)5665    as_factor(nr)5666   ##           0.4535081            0.0107198            0.1969140   ##   as_factor(nr)5698    as_factor(nr)5699    as_factor(nr)5731   ##           0.1984593            0.4502924           -0.2856565   ##   as_factor(nr)5750    as_factor(nr)5755    as_factor(nr)5772   ##          -0.1740283           -0.1905782           -0.8609714   ##   as_factor(nr)5816    as_factor(nr)5823    as_factor(nr)5851   ##          -0.0187679           -0.3477545           -0.9044465   ##   as_factor(nr)5857    as_factor(nr)5859    as_factor(nr)6016   ##          -0.0862892            0.3791638            0.4305080   ##   as_factor(nr)6020    as_factor(nr)6025    as_factor(nr)6056   ##          -0.9549249           -0.7689466           -0.4011752   ##   as_factor(nr)6094    as_factor(nr)6186    as_factor(nr)6395   ##           0.2459698            0.1857773            0.1365430   ##   as_factor(nr)6430    as_factor(nr)6446    as_factor(nr)6463   ##          -0.2188987            0.0968964           -0.2284774   ##   as_factor(nr)6558    as_factor(nr)6559    as_factor(nr)6561   ##           0.5599927            0.0003910            0.5342971   ##   as_factor(nr)6574    as_factor(nr)6648    as_factor(nr)6813   ##          -0.2562681            0.6453238           -0.0793298   ##   as_factor(nr)6824    as_factor(nr)6888    as_factor(nr)6942   ##          -0.1461823           -0.5690177            0.0183179   ##   as_factor(nr)6954    as_factor(nr)6955    as_factor(nr)6964   ##           0.5417778            0.4500903           -0.0043564   ##   as_factor(nr)6987    as_factor(nr)7025    as_factor(nr)7043   ##           1.2720637            0.3481714            0.1488308   ##   as_factor(nr)7060    as_factor(nr)7087    as_factor(nr)7238   ##           0.2119258           -0.5611468           -0.0607624   ##   as_factor(nr)7279    as_factor(nr)7342    as_factor(nr)7343   ##          -0.1919030           -0.0237805           -0.0089601   ##   as_factor(nr)7411    as_factor(nr)7424    as_factor(nr)7429   ##          -0.3824880           -0.0101679            0.0906558   ##   as_factor(nr)7454    as_factor(nr)7472    as_factor(nr)7474   ##           0.1976527           -0.0748980           -0.0093243   ##   as_factor(nr)7509    as_factor(nr)7539    as_factor(nr)7769   ##           0.0067496           -0.3042770            0.3479501   ##   as_factor(nr)7783    as_factor(nr)7784    as_factor(nr)7801   ##          -0.0634716            1.3091200           -0.4832790   ##   as_factor(nr)7824    as_factor(nr)7874    as_factor(nr)7887   ##           0.1444155            0.7831218            0.0800170   ##   as_factor(nr)7923    as_factor(nr)7926    as_factor(nr)8021   ##           0.7046102            0.2593901            0.2063953   ##   as_factor(nr)8087    as_factor(nr)8089    as_factor(nr)8090   ##           0.6271278            0.2188360            0.1581329   ##   as_factor(nr)8096    as_factor(nr)8106    as_factor(nr)8107   ##           0.1673140            0.0974152           -0.1696652   ##   as_factor(nr)8142    as_factor(nr)8168    as_factor(nr)8173   ##          -0.0643015            0.2804680            0.0359172   ##   as_factor(nr)8203    as_factor(nr)8211    as_factor(nr)8224   ##           0.7694466           -0.3648051            0.5093971   ##   as_factor(nr)8272    as_factor(nr)8300    as_factor(nr)8304   ##           0.5386226            0.0924080            0.2796535   ##   as_factor(nr)8364    as_factor(nr)8370    as_factor(nr)8381   ##           0.2509439            0.5182665           -0.3088516   ##   as_factor(nr)8388    as_factor(nr)8406    as_factor(nr)8415   ##           0.0164486           -0.0082910           -0.4285644   ##   as_factor(nr)8496    as_factor(nr)8501    as_factor(nr)8518   ##          -0.3625736           -0.5540992            0.6107016   ##   as_factor(nr)8520    as_factor(nr)8524    as_factor(nr)8548   ##          -0.4697766           -0.0468748           -0.2537187   ##   as_factor(nr)8556    as_factor(nr)8564    as_factor(nr)8581   ##           0.2608849           -0.2831687           -0.3909871   ##   as_factor(nr)8586    as_factor(nr)8587    as_factor(nr)8597   ##          -0.5064964           -0.5115870           -0.0733811   ##   as_factor(nr)8656    as_factor(nr)8722    as_factor(nr)8743   ##          -0.0526669            0.2179461            0.3876560   ##   as_factor(nr)8749    as_factor(nr)8758    as_factor(nr)8796   ##           0.0933591           -0.0441302            0.2133917   ##   as_factor(nr)8838    as_factor(nr)8842    as_factor(nr)8846   ##           0.0575352           -0.3392368           -0.2420697   ##   as_factor(nr)8860    as_factor(nr)8862    as_factor(nr)8880   ##          -0.2235111           -0.0359877            0.7517817   ##   as_factor(nr)8886    as_factor(nr)8903    as_factor(nr)8908   ##           0.0580455           -0.7769109           -0.1923077   ##   as_factor(nr)8911    as_factor(nr)8917    as_factor(nr)8991   ##          -0.4266092            0.2885122            0.4478844   ##   as_factor(nr)8997    as_factor(nr)9014    as_factor(nr)9015   ##           0.4059819            0.1657148           -0.0351953   ##   as_factor(nr)9027    as_factor(nr)9066    as_factor(nr)9082   ##           0.4343381           -0.8601727           -0.4743540   ##   as_factor(nr)9131    as_factor(nr)9132    as_factor(nr)9154   ##          -0.2932697           -0.0933988            0.8779975   ##   as_factor(nr)9158    as_factor(nr)9184    as_factor(nr)9230   ##          -0.1045911           -0.1610132           -0.4958800   ##   as_factor(nr)9265    as_factor(nr)9367    as_factor(nr)9390   ##          -0.1977154           -0.4128657           -0.4844774   ##   as_factor(nr)9391    as_factor(nr)9418    as_factor(nr)9424   ##          -0.0299420            0.7904038            0.4243795   ##   as_factor(nr)9447    as_factor(nr)9449    as_factor(nr)9453   ##          -0.3077446           -0.1947209            0.4245348   ##   as_factor(nr)9468    as_factor(nr)9502    as_factor(nr)9505   ##          -0.0323229            0.5159878           -0.3885785   ##   as_factor(nr)9603    as_factor(nr)9643    as_factor(nr)9667   ##          -0.2619756            0.2020463            0.3369007   ##   as_factor(nr)9683    as_factor(nr)9694    as_factor(nr)9710   ##          -0.3717678            0.4631701            0.1230740   ##   as_factor(nr)9718    as_factor(nr)9725    as_factor(nr)9744   ##           0.2802833           -0.0752875            0.3284672   ##   as_factor(nr)9752    as_factor(nr)9776    as_factor(nr)9786   ##           0.7241654            0.6713395            0.2011286   ##   as_factor(nr)9791    as_factor(nr)9794    as_factor(nr)9810   ##          -0.5056260            0.1197105           -0.3605671   ##   as_factor(nr)9846    as_factor(nr)9859    as_factor(nr)9868   ##           0.7610772           -0.0458501           -0.2164203   ##   as_factor(nr)9876    as_factor(nr)9883    as_factor(nr)9889   ##           0.3713277           -0.1840586            0.4380360   ##   as_factor(nr)9901    as_factor(nr)9936    as_factor(nr)9964   ##           0.2413978            0.0352408           -0.2767415   ##  as_factor(nr)10043   as_factor(nr)10067   as_factor(nr)10091   ##          -0.7534264            0.1029372            0.3028379   ##  as_factor(nr)10120   as_factor(nr)10121   as_factor(nr)10167   ##          -1.3373992           -0.0363318           -0.0088156   ##  as_factor(nr)10209   as_factor(nr)10230   as_factor(nr)10265   ##          -0.3294991            0.2384233            0.5701620   ##  as_factor(nr)10274   as_factor(nr)10311   as_factor(nr)10392   ##          -0.2657193            0.2424737           -0.6170507   ##  as_factor(nr)10425   as_factor(nr)10441   as_factor(nr)10457   ##           0.7000110           -0.0350489           -0.2657116   ##  as_factor(nr)10469   as_factor(nr)10524   as_factor(nr)10552   ##           0.3475650           -0.3469673           -0.3800088   ##  as_factor(nr)10553   as_factor(nr)10570   as_factor(nr)10593   ##           0.0645696           -1.7692078           -0.2509685   ##  as_factor(nr)10666   as_factor(nr)11275   as_factor(nr)11328   ##          -0.4183513           -0.2120244           -0.0550100   ##  as_factor(nr)11750   as_factor(nr)11821   as_factor(nr)11857   ##          -0.0403358            0.2613495            0.5374261   ##  as_factor(nr)11887   as_factor(nr)11890   as_factor(nr)11892   ##           0.3225502            0.1174285            0.6613401   ##  as_factor(nr)11924   as_factor(nr)11925   as_factor(nr)11957   ##           0.0799755           -0.0187697           -0.8699528   ##  as_factor(nr)11973   as_factor(nr)11990   as_factor(nr)12012   ##           0.2197511            0.5290434           -0.1820652   ##  as_factor(nr)12013   as_factor(nr)12045   as_factor(nr)12055   ##           0.1499400           -0.2690730            0.2934351   ##  as_factor(nr)12084   as_factor(nr)12088   as_factor(nr)12122   ##          -0.5128255           -0.4764069           -0.4007184   ##  as_factor(nr)12179   as_factor(nr)12182   as_factor(nr)12220   ##          -0.1753613            0.1061416            0.3412228   ##  as_factor(nr)12221   as_factor(nr)12245   as_factor(nr)12276   ##          -0.9974771           -0.5254311            0.1087125   ##  as_factor(nr)12385   as_factor(nr)12410   as_factor(nr)12420   ##           0.3013288           -0.6276005            0.1479143   ##  as_factor(nr)12433   as_factor(nr)12451   as_factor(nr)12477   ##           0.2379909            0.1411634            0.6686839   ##  as_factor(nr)12500   as_factor(nr)12534   as_factor(nr)12548   ##          -0.3389846            0.6202036           -0.3341063   ## as_factor(year)1981  as_factor(year)1982   ##           0.1196069            0.1775399 library(sandwich) V <- vcovCL(model, ~nr) library(broom) library(lmtest)  coeftest(model, V) %>%     tidy() %>%     filter(term == \"union\") ## # A tibble: 1 × 5 ##   term  estimate std.error statistic p.value ##   <chr>    <dbl>     <dbl>     <dbl>   <dbl> ## 1 union    0.118    0.0492      2.40  0.0164"},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/panel.html","id":"using-someone-elses-code","dir":"Articles > Art","previous_headings":"","what":"Using someone else’s code","title":"Panel Data and Fixed Effects Regression","text":"’s two main libraries probably use panel data: plm fixest. former around longer endorsed Intro Econometrics R authors. latter endorsed … , people know switching fixest. ’ll refer Section 10.3 Intro Metrics R ’re interested plm talk fixest . thing like fixest sensible treatment standard errors functions exporting regression tables. order fit fixed effect model, just need use vertical bar formula: Two things nice: doesn’t print fixed effect values like lm. can get running fixef(model), ’s printed regression output default. Also, can see clusters standard errors level first fixed effect default. correct default use, can use type standard errors like. extensive documentation author’s website talking standard errors, exception software packages. export features last thing like fixest. ’ll care lot ’re writing papers, ’s nice just one function good defaults (looks good LaTeX).","code":"library(fixest) (model <- feols(lwage ~ union | nr + year, data = data)) ## OLS estimation, Dep. Var.: lwage ## Observations: 1,635  ## Fixed-effects: nr: 545,  year: 3 ## Standard-errors: Clustered (nr)  ##       Estimate Std. Error t value  Pr(>|t|)     ## union 0.118113   0.040125 2.94364 0.0033823 **  ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## RMSE: 0.305418     Adj. R2: 0.507916 ##                  Within R2: 0.009123 setFixest_dict(     lwage = \"log(wage)\",     nr = \"Individual\",     year = \"Year\",     union = \"In union (0 or 1)\" ) etable(model) ##                               model ## Dependent Var.:           log(wage) ##                                     ## In union (0 or 1) 0.1181** (0.0401) ## Fixed-Effects:    ----------------- ## Individual                      Yes ## Year                            Yes ## _________________ _________________ ## S.E.: Clustered      by: Individual ## Observations                  1,635 ## R2                          0.67265 ## Within R2                   0.00912 ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/panel.html","id":"conclusion","dir":"Articles > Art","previous_headings":"","what":"Conclusion","title":"Panel Data and Fixed Effects Regression","text":"go , things , maybe ’s easier learn use package already . ’s fixed cost learn, constraint can package implemented. ’s discourage using extra packages, rather encouragement take challenge sometimes. learn way. Happy Coding!","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/post-estimation.html","id":"the-pattern","dir":"Articles > Art","previous_headings":"","what":"The Pattern","title":"Post-Estimation: It's All Delta Method","text":"fitting linear model, often want ask questions combinations \\(\\beta\\)s. two equal, three equal zero, \\(\\tanh \\beta_3\\) equal zero? broadly known post-estimation. endorse ’s Delta Method™ view post estimation testing. Recall Delta Method says \\(X\\) k-dimensional multivariate random normal mean \\(\\mu\\) covariance matrix \\(\\Sigma\\) \\(g:\\mathbb{R}^k \\rightarrow \\mathbb{R}^l\\) non-zero \\(l\\times k\\) derivative matrix, call \\(\\nabla\\! g\\) can approximate distribution \\(g(X)\\) normal mean \\(g(\\mu)\\) variance \\(\\nabla\\! g(\\mu) \\Sigma \\nabla\\! g(\\mu)'\\). basically first-order approximation distribution using Taylor series. Like Taylor series, \\(g\\) linear (.e. \\(g(x) = Ax\\) matrix \\(\\)), just approximation, exact. Second, remember can choose evaluate multiple hypotheses either jointly independently. evaluate independently, read standard errors diagonal variance matrix construct bunch t- z-values. evaluate jointly order test \\(g(\\mu)=0\\), construct chi-square type statistic combining hypotheses together one value. pre- post-multiplying point estimates around inverse variance matrix, .e. \\[ g(\\mu)' (\\nabla\\! g(\\mu) \\Sigma \\nabla\\! g(\\mu)') ^ {-1} g(\\mu) \\sim \\mathcal{\\chi}^2_l \\] conclusion, two questions: function linear, testing jointly independently? four possible combinations give four Stata commands used post-estimation: test, testnl, lincom, nlcom. perform Delta Method estimate distribution \\(g(X)\\), difference get : Clear mud? Let’s example.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/post-estimation.html","id":"the-implementation","dir":"Articles > Art","previous_headings":"","what":"The Implementation","title":"Post-Estimation: It's All Delta Method","text":"0.2.0 release code Stata-esque post-estimation . Let’s start estimating favorite model, returns wage based education ability score: Let’s suppose interested partial effect education wages different levels ability. partial effect \\(\\beta_{educ} + abil * \\beta_{educ * abil}\\). depends ability level. Let’s calulate 25th, 50th, 75th percentiles ability first thing might try lincom, give us point estimate partial effects. explanation warranted . First, educ `educ:abil` refer coefficients model. always look first values, global environment. Second, backticks `educ:abil` required ’s “weird” R expression writing backticks tells R consider one single variable. test `(Intercept)` well. One improvement (think) may make easier: can rename betas. names coefficients currently can use glue package generate simpler names: Now let’s use test command. tests expressions supply equal zero. Let’s test coefficients educ abil equal (.e. \\(\\beta_{educ} - \\beta_{abil} = 0\\)) commands nonlinear functions work , can use funky functions: can also supply vcov betas want. can function matrix. Lastly, note default behavior robust standard errors use generic stats::vcov function. means lm() objects homoskedastic default, feols lm_robust objects use robust standard errors default.","code":"library(tidyverse) library(haven) library(fixest)  htv <- read_dta(system.file(\"HTV.DTA\", package = \"metrics.in.r\"))  (model <- feols(lwage ~ educ * abil, data = htv, vcov = \"hc1\")) ## OLS estimation, Dep. Var.: lwage ## Observations: 1,230  ## Standard-errors: Heteroskedasticity-robust  ##              Estimate Std. Error  t value   Pr(>|t|)     ## (Intercept)  1.244587   0.138658  8.97595  < 2.2e-16 *** ## educ         0.084207   0.011709  7.19164 1.1108e-12 *** ## abil         0.114310   0.041425  2.75948 5.8756e-03 **  ## educ:abil   -0.005061   0.003290 -1.53812 1.2428e-01     ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## RMSE: 0.53456   Adj. R2: 0.186697 abil_25 <- quantile(htv$abil, 0.25) abil_50 <- median(htv$abil) abil_75 <- quantile(htv$abil, 0.75) library(metrics.in.r)  lincom(model,     educ + abil_25 * `educ:abil`,     educ + abil_50 * `educ:abil`,     educ + abil_75 * `educ:abil`     ) ## # A tibble: 3 × 7 ##   Expression    Estimate `Std. Error` `t-Value` `Pr(>|t|)` `CI Lower` `CI Upper` ##   <chr>            <dbl>        <dbl>     <dbl>      <dbl>      <dbl>      <dbl> ## 1 educ + abil_…   0.0813      0.0106       7.69   3.09e-14     0.102      0.0606 ## 2 educ + abil_…   0.0733      0.00887      8.27   3.48e-16     0.0907     0.0559 ## 3 educ + abil_…   0.0667      0.00960      6.95   5.98e-12     0.0855     0.0479 names(coef(model)) ## [1] \"(Intercept)\" \"educ\"        \"abil\"        \"educ:abil\" library(glue)  lincom(model,     b2 + abil_25 * b4,     b2 + abil_50 * b4,     b2 + abil_75 * b4,     params = glue(\"b{1:4}\") # equal to c(\"b1\", \"b2\", \"b3\", \"b4\")     ) ## # A tibble: 3 × 7 ##   Expression    Estimate `Std. Error` `t-Value` `Pr(>|t|)` `CI Lower` `CI Upper` ##   <chr>            <dbl>        <dbl>     <dbl>      <dbl>      <dbl>      <dbl> ## 1 b2 + abil_25…   0.0813      0.0106       7.69   3.09e-14     0.102      0.0606 ## 2 b2 + abil_50…   0.0733      0.00887      8.27   3.48e-16     0.0907     0.0559 ## 3 b2 + abil_75…   0.0667      0.00960      6.95   5.98e-12     0.0855     0.0479 ## ℹ Where b1=(Intercept), b2=educ, b3=abil, b4=educ:abil test(model, educ - abil) ## Joint F Test of the linear hypotheses ## • educ - abil = 0 ##                F(1,1226) = 0.686609                ##                  Pr(>F) = 0.407481 nlcom(model, sin(educ), sqrt(abil)) ## # A tibble: 2 × 7 ##   Expression Estimate `Std. Error` `Z-Value` `Pr(>|z|)` `CI Lower` `CI Upper` ##   <chr>         <dbl>        <dbl>     <dbl>      <dbl>      <dbl>      <dbl> ## 1 sin(educ)    0.0841       0.0117      7.21   5.65e-13      0.107     0.0612 ## 2 sqrt(abil)   0.338        0.0613      5.52   3.41e- 8      0.458     0.218 library(sandwich) model %>% test(educ - abil, vcov. = vcovHC(., type = \"HC1\")) ## Joint F Test of the linear hypotheses ## • educ - abil = 0 ##                F(1,1226) = 0.686609                ##                  Pr(>F) = 0.407481"},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/post-estimation.html","id":"the-nitty-gritty-it-really-all-is-delta-method","dir":"Articles > Art","previous_headings":"","what":"The Nitty Gritty: It Really All is Delta Method","title":"Post-Estimation: It's All Delta Method","text":"go code look definitions functions, may seem weird: ’s ! simple? postEstimation function? code:  First, note postEstimation function returns function, sometimes known function factory. Note argument, clazz, used right end, line 25. rest function ? Lines 8–21 just housekeeping. give params argument, change names coefficient vector match . lines 15–21 ’m just resolving covariance betas given different options supplying . real work line 23, deltaMethod. deltaMethod function returns point estimate covariance post-estimation hypotheses. bit digression… refer interested reader metaprogramming chapter Advanced R reference page basic symbolic differentiation R. point , ’s just Delta Method.  difference post-estimation commands class returned object. just write specialized method one returns summary table, example test. calculate f-statistic, just object printed .  really want emphasize point post-estimation commands RETURN EXACT OBJECT. printed screen differs command, underlying object exact .","code":"test <- postEstimation(\"test\") tesnl <- postEstimation(\"testnl\") lincom <- postEstimation(\"lincom\") nlcom <- postEstimation(\"nlcom\")"},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/post-estimation.html","id":"conclusion","dir":"Articles > Art","previous_headings":"","what":"Conclusion","title":"Post-Estimation: It's All Delta Method","text":"Hopefully gives starting point R. Keep mind two distinctions: whether linear nonlinear, whether jointly independently testing hypotheses. lead pick one among test, testnl, lincom, nlcom. ’s Delta Method, particular test statistic choose different one. write code ? Surely ways post-estimation R. problem found one works seamlessly Stata . car package deltaMethod linearHypothesis functions, aod package wald.test function. definitely stitch together get job done. issue difficulty stitching together friction drives people away R towards Stata. want smooth bumps make easier people stop paying nose mediocre software. hopefully code helps . Happy Coding!","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/rmarkdown-intro.html","id":"the-pattern-literate-programming","dir":"Articles > Art","previous_headings":"","what":"The Pattern: Literate Programming","title":"Digression: A Taste of RMarkdown","text":"Literate Programming concept almost forty years old—much older modern computing . pioneered famous computer scientist Donald Knuth. quote literate programming sums perfectly: Instead imagining main task instruct computer , let us concentrate rather explaining human beings want computer . literate programming, primary output report, presentation, document intended human consumption. However, able scatter chunks computer code throughout document, executed output interleaved document. means “processing” steps turning literate programs finished output. typically called tangling, extracting computer code document executing ; weaving, inserting results execution document compiling finished output. entire process tangling weaving sometimes called knitting.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/rmarkdown-intro.html","id":"the-horror-its-latex","dir":"Articles > Art","previous_headings":"","what":"The Horror: It’s LaTeX 😱","title":"Digression: A Taste of RMarkdown","text":"Due historical context literate programming evolved (due fact Donald Knuth invented LaTeX), literate programs used LaTeX produced PDF documents output. ’s still case today, ’s really better engine generating PDFs academic reports. uninitiated, LaTeX programming language producing documents—think “Microsoft Word programming language.” LaTeX can intimidating newcomers, definitely learning curve. Fortunately, ways can “abstract” away difficulties working LaTeX write document using much simpler markdown syntax. markdown converted LaTeX make pretty PDFs. upshot need install LaTeX computer. RMarkdown creator Yihui Xie done lot work try make easy R users. R package called tinytex downloading minimal version LaTeX. can check . downside may contain LaTeX packages need. hard install new LaTeX packages, just kind annoying. option install called “LaTeX distribution,” LaTeX plus bunch packages, applications, etc. large can take 6+ GB memory computer. upside LaTeX packages ever use life included, spared annoyance installing missing LaTeX packages. can read LaTeX distributions .","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/rmarkdown-intro.html","id":"introducing-rmarkdown","dir":"Articles > Art","previous_headings":"","what":"Introducing RMarkdown","title":"Digression: A Taste of RMarkdown","text":"Now understand little bit mechanics literate programming, let’s introduce RMarkdown. need install one additional R package, knitr. package business compiling documents. create new RMarkdown file, select dropdown top left corner RStudio:  Choose name document, make sure output type PDF. document generated example commands show can RMarkdown. delete keep two things: header, also called metadata. starts ends three dashes, ---. can set different properties document, including controlling output generated. come back second. setup code chunk, R code “sets ” environment rest RMarkdown document. good place set default knitr options, load libraries ’ll using.  order create PDF, just need click “knit” button toolbar. PDF preview open separate window document knits.","code":""},{"path":[]},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/rmarkdown-intro.html","id":"markdown-syntax-and-math-equations","dir":"Articles > Art","previous_headings":"What can I do with RMarkdown?","what":"Markdown syntax and math equations","title":"Digression: A Taste of RMarkdown","text":"Markdown syntax pretty easy work . Different special symbols tell markdown text formatted certain ways. can create headers, create lists, italicize things, bold , create links, insert images, . many cheatsheets can Google, one example. quick flavor markdown .    math equations wrote actually LaTeX equations. Since eventually turning markdown file LaTeX, can also just include LaTeX directly case. nice cheatsheet math symbols LaTeX can found .","code":""},{"path":[]},{"path":[]},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/rmarkdown-intro.html","id":"r-code-chunks","dir":"Articles > Art","previous_headings":"What can I do with RMarkdown?","what":"R Code Chunks","title":"Digression: A Taste of RMarkdown","text":"can create “code chunk” inserting three backticks curly braces letter R , like :  Three backticks terminates code chunk. (Hot tip: letter “r” language code chunk, can also use “python” “julia” language want.) happens knit document R code displayed document, results executing R code displayed . code chunks run linearly, can include variables defined previous code chunks. output code chunk :  can include options control code chunk evaluated, like :  good ones know eval = FALSE want display code actually run echo = FALSE want run code show output show code many options can add, control plot size adding captions plots. can see Yihui’s website .","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/rmarkdown-intro.html","id":"two-tricks-before-you-go","dir":"Articles > Art","previous_headings":"","what":"Two Tricks Before You Go","title":"Digression: A Taste of RMarkdown","text":"way “pretty print” data frames RMarkdown. means code chunk returns data frame passed special print method makes nice LaTeX table. ’ll show two examples . enable , change header look like :","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/rmarkdown-intro.html","id":"tidy-your-regression-output","dir":"Articles > Art","previous_headings":"Two Tricks Before You Go","what":"Tidy Your Regression Output","title":"Digression: A Taste of RMarkdown","text":"library called broom R tidy regression summaries turn data frames. just pass either result summary coeftest tidy() function, like :  changed header, now pretty print regression summaries, like :  Note output summary() commands, print coefficient table, R squared, F statistic, MSE. matters , consider different way presenting model summary.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/rmarkdown-intro.html","id":"easy-summary-statistics","dir":"Articles > Art","previous_headings":"Two Tricks Before You Go","what":"Easy Summary Statistics","title":"Digression: A Taste of RMarkdown","text":"skimr library implements great utility print descriptive statistics datasets. function want use called skim_without_charts. produces output looks like (pretty printing enabled):  row output different variable htv, columns present different summary statistics. Remember p0 minimum, p50 median, p100 maximum. Instead summarizing entire dataset, list variables want summarize, like :","code":"htv %>% skim_without_charts(wage, abil, educ)"},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/rmarkdown-intro.html","id":"conclusion","dir":"Articles > Art","previous_headings":"","what":"Conclusion","title":"Digression: A Taste of RMarkdown","text":"Hopefully gives enough information get started using RMarkdown homeworks. general, RMarkdown provides us clean, relatively painless way literate programming. Remember markdown becomes LaTeX becomes PDF. many good resources learning RMarkdown. entire book available free online, well cookbook gives solutions “recipes” common tasks. also cheatsheet available . point many cheatsheets topics besides RMarkdown available link, extremely handy. ’re technical reader, detailed reference RMarkdown .","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/rmarkdown-intro.html","id":"postscript-other-document-types-other-outputs","dir":"Articles > Art","previous_headings":"","what":"Postscript: Other document types? Other outputs?","title":"Digression: A Taste of RMarkdown","text":"First, say RMarkdown can output lot PDFs. can create blogs, books, websites, HTML pages, PowerPoint presentations, interactive (Shiny) documents, . ’s beyond scope article, can find many resources different output types links provided . Second, “literate programming” document types may heard , namely .Rnw .qmd. Rnw stands “R noweb” older RMarkdown—goes back system designed Donald Knuth. literally LaTeX document, R code sprinkled . can see example splines.Rnw document posted Canvas ’re interested. ’re already proficient LaTeX, might like amount control gives . don’t like size learning curve, prefer teach .Rmd first. .qmd file extension stands “Quarto Markdown.” RStudio announced year (2022) rebranding Quarto releasing new literate programming tool called Quarto Markdown. de-emphasizes R intended multi-lingual data science audience can produce documents using language. eventually replacement RMarkdown, opinion still bit new. documentation bigger user base, beginner friendly start teaching instead RMarkdown. Happy Coding!","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/robust-ses.html","id":"sandwich-does-it-all","dir":"Articles > Art","previous_headings":"","what":"sandwich does it all","title":"Robust Standard Errors","text":"sandwich R package Swiss army knife can lot comes robust standard errors. ’s called “sandwich” variance estimators tend form looks like sandwich: ’s \\(Q_{XX}Q_{u^2XX}Q_{XX}\\) form may familiar . Either way, think ’s cute name. Let’s recreate model used intro article. Now load sandwich package. different functions sandwich, correspond different types robust variance estimators: vcovHC classic “White’s” (heteroskedasticity-consistent) standard errors; vcovCL clustered standard errors; vcovBS boostrapped standard errors. Making covariance matrix \\(\\beta\\) estimates given regression model easy calling vcovHC model. type argument optional: different types “corrections” heteroskedasticity-robust standard errors, HC1 correction Stata uses default. now , ’ll omit type argument keep R code cleaner. robust covariance matrix, can get robust standard errors \\(\\beta\\) estimates taking square root diagonal: Another way pipe operator: won’t explain pipe operator now. prefer “immersive” introduction now, cover -depth later. Just notice sort “unwraps” nested function calls reverses order calls.","code":"library(tidyverse) library(haven)  htv <- read_dta(system.file(\"HTV.DTA\", package = \"metrics.in.r\")) model <- lm(wage ~ educ * abil, data = htv) library(sandwich) vcovHC(model, type = \"HC1\") ##             (Intercept)         educ        abil    educ:abil ## (Intercept)  3.47283828 -0.305897247 -0.24542291  0.030789574 ## educ        -0.30589725  0.027454256  0.02829398 -0.003324115 ## abil        -0.24542291  0.028293984  0.43706077 -0.035738635 ## educ:abil    0.03078957 -0.003324115 -0.03573864  0.003002688 sqrt(diag(vcovHC(model))) ## (Intercept)        educ        abil   educ:abil  ##  1.87304779  0.16649606  0.66783405  0.05534231 model %>% vcovHC %>% diag %>% sqrt"},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/robust-ses.html","id":"but-what-about-the-pretty-tables","dir":"Articles > Art","previous_headings":"","what":"But what about the pretty tables","title":"Robust Standard Errors","text":"Recall intro article model get nice summary table summary table generated homoskedastic assumption variance residuals, need figure something else robust standard errors. Luckily, package called lmtest provides functionality. call coeftest function give model covariance matrix, print nice summary table like : , pipe look like expend little effort get covariance matrix \\(\\beta\\) estimates, model covariance matrix, can make summary table. fact, really . ’m going give demonstration need summary tables model covariance matrix. Let’s replicate output coeftest—don’t need understand ’m , just notice objects ’m using model covariance matrix.","code":"summary(model) ##  ## Call: ## lm(formula = wage ~ educ * abil, data = htv) ##  ## Residuals: ##     Min      1Q  Median      3Q     Max  ## -17.943  -4.602  -1.184   2.420  69.450  ##  ## Coefficients: ##             Estimate Std. Error t value Pr(>|t|)     ## (Intercept) -0.65484    1.97210  -0.332    0.740     ## educ         0.98368    0.16900   5.821 7.48e-09 *** ## abil        -0.40005    0.56506  -0.708    0.479     ## educ:abil    0.06939    0.04565   1.520    0.129     ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ##  ## Residual standard error: 8.438 on 1226 degrees of freedom ## Multiple R-squared:  0.1388, Adjusted R-squared:  0.1367  ## F-statistic: 65.88 on 3 and 1226 DF,  p-value: < 2.2e-16 library(lmtest) coeftest(model, vcov. = vcovHC(model)) ##  ## t test of coefficients: ##  ##              Estimate Std. Error t value  Pr(>|t|)     ## (Intercept) -0.654839   1.873048 -0.3496    0.7267     ## educ         0.983682   0.166496  5.9081 4.477e-09 *** ## abil        -0.400051   0.667834 -0.5990    0.5493     ## educ:abil    0.069387   0.055342  1.2538    0.2102     ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 model %>% coeftest(vcov. = vcovHC(.)) estimate <- coef(model) std_error <- model %>% vcovHC %>% diag %>% sqrt t_value <- estimate / std_error p_value <- 2 * pt(-abs(t_value), df = df.residual(model))  cbind(estimate, std_error, t_value, p_value) ##                estimate  std_error    t_value      p_value ## (Intercept) -0.65483870 1.87304779 -0.3496113 7.266905e-01 ## educ         0.98368161 0.16649606  5.9081373 4.477086e-09 ## abil        -0.40005124 0.66783405 -0.5990279 5.492649e-01 ## educ:abil    0.06938703 0.05534231  1.2537791 2.101613e-01"},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/robust-ses.html","id":"there-are-easier-alternatives","dir":"Articles > Art","previous_headings":"","what":"There are easier alternatives","title":"Robust Standard Errors","text":"Since R lot people using , makes sense someone written something make robust standard errors easier. Two people fact. first lm_robust function estimatr package. specify covariance type create model, summary function use correct type robust standard errors output: second (preferred) method feols function fixest package. Just like lm_robust, specify covariance type create model: word warning: issues computing clustered standard errors lm_robust. general, don’t trust results lm_robust give much trust sandwich fixest. Keep mind choose wisely. show lm_robust still many people use . convince switch fixest 🙂","code":"library(estimatr)  model <- lm_robust(wage ~ educ * abil, data = htv, se_type = \"HC1\")  summary(model) ##  ## Call: ## lm_robust(formula = wage ~ educ * abil, data = htv, se_type = \"HC1\") ##  ## Standard error type:  HC1  ##  ## Coefficients: ##             Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper   DF ## (Intercept) -0.65484     1.8636 -0.3514 7.254e-01 -4.31095   3.0013 1226 ## educ         0.98368     0.1657  5.9368 3.780e-09  0.65861   1.3088 1226 ## abil        -0.40005     0.6611 -0.6051 5.452e-01 -1.69708   0.8970 1226 ## educ:abil    0.06939     0.0548  1.2663 2.057e-01 -0.03812   0.1769 1226 ##  ## Multiple R-squared:  0.1388 ,    Adjusted R-squared:  0.1367  ## F-statistic: 61.57 on 3 and 1226 DF,  p-value: < 2.2e-16 library(fixest)  model <- feols(wage ~ educ * abil, data = htv, vcov = \"HC1\")  summary(model) ## OLS estimation, Dep. Var.: wage ## Observations: 1,230  ## Standard-errors: Heteroskedasticity-robust  ##              Estimate Std. Error   t value   Pr(>|t|)     ## (Intercept) -0.654839   1.863555 -0.351392 7.2535e-01     ## educ         0.983682   0.165693  5.936763 3.7799e-09 *** ## abil        -0.400051   0.661106 -0.605124 5.4521e-01     ## educ:abil    0.069387   0.054797  1.266261 2.0566e-01     ## --- ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## RMSE: 8.42455   Adj. R2: 0.136723"},{"path":"https://nateybear.github.io/metrics-in-r/articles/art/robust-ses.html","id":"conclusion-whyd-you-show-me-the-hard-way","dir":"Articles > Art","previous_headings":"","what":"Conclusion: Why’d you show me the hard way?","title":"Robust Standard Errors","text":"Two reasons showed sandwich coeftest method. One want demystify little bit going behind scenes. need model covariance matrix. , can compute standard errors, t statistics, p values. prefer using sandwich exactly reason: don’t like “magic” functions much without realizing going . second reason sandwich coeftest method remains enduringly popular. lm_robust moment fame, fixest coming popular library econometrics, sometimes just want simple, tried--true method. can choose method ’d like use. Happy Coding!","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/zen/anatomy-1.html","id":"the-pattern","dir":"Articles > Zen","previous_headings":"","what":"The Pattern","title":"Anatomy of an R Project: Overview","text":"’re academic project, want self-contained environment keep data, write scripts, compile finished product (report, slides, etc.). R, concept known R “project.” patterns around R projects want introduce writeup create project project workflow looks like organize files refer consistently using package track changes share progress GitHub track dependencies renv package topics worthy writeup . give high-level summary action items remember. subsequent writeups dive individual topic. can take whatever order want; come back end review takeaways.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/zen/anatomy-1.html","id":"always-use-r-projects","dir":"Articles > Zen","previous_headings":"","what":"Always use R Projects","title":"Anatomy of an R Project: Overview","text":"Creating R Project nothing creating .Rproj file folder, folder considered R Project RStudio. different thing work different R project. files store configuration, also just important organizational concept. Open R project double-clicking .Rproj file, RStudio loads project “fresh” new window. using RStudio, can type R code console experiment, can write code file “source” file run . Never just use console writing code. can tinker console, eventually needs saved file can reproduce . Never save workspace data exit exact reason: spend hours hours tinkering something get perfect never write got way, remember peer/supervisor/journal editor asks replication code?","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/zen/anatomy-1.html","id":"be-militant-with-file-structure","dir":"Articles > Zen","previous_headings":"","what":"Be Militant with File Structure","title":"Anatomy of an R Project: Overview","text":"Always make file structure self-evident. Data, figures, tables go different folders. R code produce given dataset/figure/table lives file whose name corresponds name thing generates. obvious TA can open GitHub repository give grade work without explanation . bonus points, use build tool like Makefile targets file. package allows refer files inside project consistent way. Always use refer files project. Refer relative base folder project. way makes file references work anywhere project anyone runs code. Avoid absolute file references like plague.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/zen/anatomy-1.html","id":"one--rproj-one-github-repository","dir":"Articles > Zen","previous_headings":"","what":"One .Rproj = One GitHub Repository","title":"Anatomy of an R Project: Overview","text":"GitHub place store code. Use . Students free access GitHub Pro can create private repositories. natural association R Projects GitHub repositories one--one. Using Git tab RStudio makes super easy commit/push/pull click button. Consider using GitHub even aren’t working others sharing project publicly. ’s like ready-made backup code computer crashes ’re issues. share project publicly, think GitHub coding résumé.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/zen/anatomy-1.html","id":"lockfiles-to-lock-in-dependencies","dir":"Articles > Zen","previous_headings":"","what":"Lockfiles to Lock In Dependencies","title":"Anatomy of an R Project: Overview","text":"Using renv helps keep track versions R packages using. helps reproducibility even . don’t tell people packages need install run code. install renv project, automatically activate time open project. Remember run renv::snapshot() commit new code.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/zen/anatomy-1.html","id":"conclusion","dir":"Articles > Zen","previous_headings":"","what":"Conclusion","title":"Anatomy of an R Project: Overview","text":"Project structure management epitome Zen Programming mentioned intro article. Stay disciplined setup project, write code R scripts, keep file structure project clean. Failure can cause headaches, headaches take away main goal writing code producing research. Happy Coding!","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/zen/anatomy-2.html","id":"lets-start-a-new-project","dir":"Articles > Zen","previous_headings":"","what":"Let’s Start a New Project","title":"Anatomy of an R Project: The Project Itself","text":"project picker top-right corner RStudio:  clicking dropdown, can switch projects start new one. Go ahead click “New Project.” see dialog box pop :  can see, multiple options creating new project. already code written folder, can select “existing directory” turn folder R project. GitHub repository created, can select “version control” check project git (see article git GitHub info). ’re starting fresh, can choose “new directory” create new folder. choose “new directory,” options choose . want select “New Project” project type, recommend checking “git” “renv” boxes. ’ll cover two things later articles. created project using “New Directory” option called test. screenshot RStudio looked like afterwards . open new project, see RStudio window refresh, “clean” instance R. environment tab empty, files tab open wherever project lives computer. project picker now show name new project, see one (many) new files created. important file right now .Rproj file got created. ’ll discuss file next.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/zen/anatomy-2.html","id":"what-actually-is-an-r-project","dir":"Articles > Zen","previous_headings":"","what":"What Actually Is an R Project?","title":"Anatomy of an R Project: The Project Itself","text":"way RStudio knows folder R project .Rproj file. file just stores minimal configuration. ’s example .Rproj file one projects GitHub:  configuration stored files important. importance mainly signals RStudio folder project. signal RStudio come many benefits, described . touched first point already, subsequent points covered depth later articles. Whenever open project, greeted fresh clean RStudio window. note can also open R projects double-clicking .Rproj file . package looks .Rproj file helps easily locate files relative folder .Rproj file . RStudio Git tab automatically activated inside R project, letting sync code GitHub click button. renv package “bootstraps” (starts starts running) project loads.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/zen/anatomy-2.html","id":"what-a-fresh-clean-window-is-worth","dir":"Articles > Zen","previous_headings":"","what":"What a “Fresh Clean Window” is Worth","title":"Anatomy of an R Project: The Project Itself","text":"Creating using projects part workflow keeps disciplined researcher. start fresh every time open RStudio, forced write work file. several ways coding work RStudio. console bottom left-hand corner, can type line R code, hit enter, immediately see results. can think “instant feedback” line code. Alternatively, can create new R file write series commands top left-hand corner, click “Source” button run commands . philosophy workflow RStudio inherently experimental thing. invited type code console, run , inspect output, tinker satisfied results. However, point, need WRITE file! Create new R script write exact commands Step 1 Step N, next time open “fresh” RStudio window, can click “Source” button beautiful object replicated workspace just . essence reproducibility. Toward end, recommend disabling “Save workspace .RData exit” setting RStudio. can access setting clicking project picker selecting “Project Options” bottom menu. Disabling setting means workspace deleted every time exit RStudio, recover variables working . good thing opinion, forces write everything scripts way can always recover work start new session.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/zen/anatomy-2.html","id":"conclusion","dir":"Articles > Zen","previous_headings":"","what":"Conclusion","title":"Anatomy of an R Project: The Project Itself","text":"guide sort overview projects look like R. might realized, part appeal R projects enable lot features talk subsequent articles. pattern want start thinking projects isolated, reproducible environments. contain code data files, also “meta information” makes possible others download code data reproduce results. Along lines, love revel fact RStudio wonderful environment tinker experiment. However, also discipline realize eventually, need write concrete steps produce results . Happy Coding!","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/zen/anatomy-3.html","id":"the-pattern","dir":"Articles > Zen","previous_headings":"","what":"The Pattern","title":"Anatomy of an R Project: File Structure","text":"File structure can non-trivial thing projects. Badly structured projects confusing—don’t know comes can’t tell heads tails. File names meaningful, folders put meaningful. code, can create consistent way refer . focus article. give philosophy file organization, specific example used . replication assignment, can find . example intended --end-. Take guideline work.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/zen/anatomy-3.html","id":"data","dir":"Articles > Zen","previous_headings":"","what":"Data","title":"Anatomy of an R Project: File Structure","text":"’re running research project, probably using data. using data, probably need clean somehow. Keep data folder called “data.” need clean , write R script inside folder called “R” subfolder reserved data cleaning/building tasks. example call folder “build.”  name R script corresponds name data set cleans. reads “raw” data file, applies whatever transformations necessary arrive “clean” dataset, writes clean dataset new file. point exactly document steps get dataset find Internet wild dataset use regressions.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/zen/anatomy-3.html","id":"tables-and-figures","dir":"Articles > Zen","previous_headings":"","what":"Tables and Figures","title":"Anatomy of an R Project: File Structure","text":"’re writing report, probably figures tables need include. write R scripts read cleaned data generate output .png (figures) .tex (tables). data, figures tables live clearly marked folders. R scripts generate figures tables names correspond figures tables create. example project, made subfolder R directory called “output” code generate tables figures: ’re creating figure, reading cleaned dataset, possibly cleaning, generating graph. strongly recommend using ggplot2 package. can use ggsave() function write graph png file. tables, often data frame represents table want put paper. kableExtra package utilities generate pretty LaTeX table data frame, can write file using tidyverse function write_lines(). times, may want output regression summary table. can either use tidy() function broom package turn summary data frame, follow kableExtra steps ; can use stargazer package generate pretty regression output. trade-two stargazer gives much ---box functionality, ’s naturally harder configure specific use case.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/zen/anatomy-3.html","id":"where-are-my-files-here-they-are-","dir":"Articles > Zen","previous_headings":"","what":"Where are my files? here they are.","title":"Anatomy of an R Project: File Structure","text":"’ve talked lot reading writing files article, obviously little bit nuance want impart . different ways can refer files code. first absolute path file. tells computer find file top filesystem. example, dataset R project called “-project” look like /Users/nate/workspace/-project/data/some_dataset.csv computer. can tell path absolute path begins forward slash, /. Absolute paths can also start tilde, ~, indicates location relative home directory user. home directory /Users/nate computer, ~/workspace/-project/data/some_dataset.csv /Users/nate/workspace/-project/data/some_dataset.csv thing. absolute file paths bad? work computer. else runs code, change path file wherever project located computer. better ways . avoid absolute paths costs, lose points assignments see absolute path code. second way refer files via relative path. tells computer find file relative folder ’m currently . Usually, folder holds R script running. Relative paths can identified start ./ ../. code clean some_dataset.csv file lives ~/workspace/-project/R/build/some_dataset.R (, lives inside “build” folder inside “R” folder project), can refer dataset file R code writing ../../data/some_dataset.csv. means, “Go one folder (‘R’ folder), go another folder (‘-project’ folder), go data folder, find some_dataset.csv .” Two dots, ../, refers script’s parent folder, one dot, ./, refers folder currently . cases, one dot can implicit: hence, my_script.R ./my_script.R refer thing. relative file paths bad? usually work multiple computers relative nature. However, prone break reorganize code. Say example started code one R folder, later decide move code multiple subfolders, like R/build R/output. happens, path data file longer ../data/my_dataset.csv, ’s now ../../data/my_dataset.csv. clear worst thing world, relative file paths acceptable many software engineering contexts. purposes, can better, though. ideal way refer files projects via project-relative path. tells computer, “Look closest .Rproj file, look relative folder file.” ideal runs multiple computers robust reorganizing R scripts. way R easy. load library, use () function whenever refer file. , dataset working entire time referred (\"data/my_dataset.csv\"). may seem little abstract, can find plenty usages example project linked. One instance code generating figure. One thing keep mind : project-specific. means don’t project open RStudio wrong project open, able find files correctly. work projects way suggested , issue since always project open.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/zen/anatomy-3.html","id":"conclusion","dir":"Articles > Zen","previous_headings":"","what":"Conclusion","title":"Anatomy of an R Project: File Structure","text":"militant file naming. Follow file structure self-evident. fits perfectly “consistent predictable” mantra meditation programming. package gives consistent predictable way refer files inside project.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/zen/anatomy-3.html","id":"bonus-build-tools","dir":"Articles > Zen","previous_headings":"","what":"Bonus: Build Tools","title":"Anatomy of an R Project: File Structure","text":"enough make code self-evident someone else can figure run scripts compile project. take step , can use build tools Makefile targets file. step--step recipes build projects. common vocabulary words tools use “target” “dependency.” target something want produce—think cleaned dataset, figure, LaTeX report. dependency describes target needs run. Build tools track dependencies targets need rebuilt dependency changes. means may many scripts need run take long time run together, using build tool, build targets small parts project actually changed. Make file-based build tool, configured using file appropriately called Makefile. Make’s targets dependencies specified files exist project, Make determines target needs rebuilt comparing last modified time target file last modified time dependencies. Make concept almost software engineers familiar , preferred build tool. one drawback file-based, inherently structure project every target file (opposed configuring targets inside R code). good guide Make data scientists can found . alternative Make targets R package. Instead file-based, write R code describe build process. targets determines whether target needs rebuilt comparing hashes (strings letter uniquely identify objects code) dependencies. interesting concept personally haven’t used project yet. can read targets package . Whichever build tool use, one nice perk can configure Build tab top right-hand corner RStudio work build tool. Build tab, click “Build ” button project built! worry running scripts right order. build tools sound good , cool. ’s beyond scope article go depth, ’s interesting subject. ’re student feel free reach talk . Happy Coding!","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/zen/anatomy-4.html","id":"the-pattern","dir":"Articles > Zen","previous_headings":"","what":"The Pattern","title":"Anatomy of an R Project: Version Control","text":"Like intelligent person, probably want keep backups code handy case computer catches fire burns crisp. known broadly “version control.” far widely used form version control coding world program called git, GitHub website can store git projects. article walk get starting using git GitHub coding projects. NOTE: vast array information available git online since popular. Oftentimes new programmers find information intimidating! Don’t let scare away using git projects. git program capable supporting massive, complex projects, naturally complex . need use small subset functionality , try highlight workflow get running relatively quickly.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/zen/anatomy-4.html","id":"some-definitions","dir":"Articles > Zen","previous_headings":"","what":"Some Definitions","title":"Anatomy of an R Project: Version Control","text":"First, let’s define terms relating git GitHub. git program runs command line. GitHub website stores git projects. command line OG computer. computers mice screens graphics things click , interacted computers via text. , type command computer, prints text screen giving result command. command line still exists even though mice fancy screens graphics icons, can helpful programming. RStudio command line built . bottom left corner, called “Terminal”:  rest tutorial, whenever say enter something command line, mean type . also note terms “command line,” “terminal,” “shell” generally used interchangeably, use interchangeably tutorial. think generally good thing know use command line, definitely learning curve can mostly avoid using point--click tools RStudio. article one exception get hands dirty command line, try minimize command line usage much possible general. ’s interesting commands terminal just files! special type file operating systems called executable file. first word command type terminal name file, rest words type given file separate values called command arguments simply “args.” example, one command type second git push --set-upstream. means run git file, run two args: push --set-upstream. command line finds git file looking somewhere called PATH. Try typing shell: folders terminal search executable file, order, separated colons. like see terminal found git executable file, can use command: Since R scripts files, might naturally wonder can run R scripts like terminal. answer yes: see tutorial explanation. don’t generally recommend , since can confusing others understand ’re . git program actual business creating backups code. can make backups folder choose computer. git repository one folder making backups . purposes, folder making backups one R project. remember: one R project = one git repository. GitHub website can store git repositories. also called git remote… saves git repository remote place. individual “snapshot” backup code git called commit. commit represents small change files code. add messages commits label can remember changed commit. git stores diff files commit, .e. stores changed files. makes commits lightweight terms storage space, encouraged make many commits make easier keep track work. Commits represent distinct unit work completed, example new feature, new dataset R script clean , set edits paper/presentation. ’s important remember commits local version git. eventually push GitHub copy local backup GitHub’s servers. working people, also push work GitHub repository. pull work GitHub local computer sync changes, may possibly merge changes conflicts. conclusion, git/GitHub workflow looks like : make commits take snapshots code, push GitHub. ’re working others, periodically pull changes GitHub merge . Merges can little bit complicated won’t cover . comes time learn , Google friend. also things git/GitHub called branches pull requests can look interested learning , ’s beyond scope article. digress: Let’s get setup git GitHub start using !","code":"echo $PATH #> /opt/hostedtoolcache/Python/3.8.18/x64/bin:/opt/hostedtoolcache/Python/3.8.18/x64:/home/runner/.local/bin:/opt/pipx_bin:/home/runner/.cargo/bin:/home/runner/.config/composer/vendor/bin:/usr/local/.ghcup/bin:/home/runner/.dotnet/tools:/snap/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin which git #> /usr/bin/git"},{"path":"https://nateybear.github.io/metrics-in-r/articles/zen/anatomy-4.html","id":"get-everything-configured","dir":"Articles > Zen","previous_headings":"","what":"Get Everything Configured","title":"Anatomy of an R Project: Version Control","text":"Configuration always hard part. get everything setup smooth sailing. tools need job : git command line program. comes pre-installed Mac Linux computers, Windows. Windows users can download git git Windows website . GitHub account. Don’t pick stupid username like “nateybear” stuck forever 🙃 student, get GitHub Pro free. GitHub Pro allows create private repositories, great storing homework confidential/non-public things. gh command line program. command line program allows configure GitHub account use local git, push GitHub, GitHub knows . Download gh program .","code":""},{"path":[]},{"path":"https://nateybear.github.io/metrics-in-r/articles/zen/anatomy-4.html","id":"login-to-github","dir":"Articles > Zen","previous_headings":"Get Everything Configured > Easy as 1,2,…","what":"1. Login to GitHub","title":"Anatomy of an R Project: Version Control","text":"Type gh auth login terminal hit enter. asked series questions, can answer arrow keys enter key. answers questions blue: redirected web browser can login GitHub authorize computer.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/zen/anatomy-4.html","id":"configure-git-to-use-github-credentials","dir":"Articles > Zen","previous_headings":"Get Everything Configured > Easy as 1,2,…","what":"2. Configure git to use GitHub credentials","title":"Anatomy of an R Project: Version Control","text":"Run gh auth setup-git. tells git look login information pushing GitHub.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/zen/anatomy-4.html","id":"done","dir":"Articles > Zen","previous_headings":"Get Everything Configured > Easy as 1,2,…","what":"3. Done","title":"Anatomy of an R Project: Version Control","text":"Surely can’t easy? Hopefully , sometimes isn’t. ’re student, feel free email ’ve issues. check everything worked smoothly, run git config --get github.user get GitHub user git configured , make sure GitHub username returned.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/zen/anatomy-4.html","id":"setup-your-project-to-use-gitgithub","dir":"Articles > Zen","previous_headings":"","what":"Setup your project to use git/GitHub","title":"Anatomy of an R Project: Version Control","text":"two ways start project using git GitHub. can create project GitHub first download computer, can create project locally computer first push GitHub. don’t opinion better, ’ll describe can pick method works .","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/zen/anatomy-4.html","id":"github-first","dir":"Articles > Zen","previous_headings":"Setup your project to use git/GitHub","what":"GitHub First","title":"Anatomy of an R Project: Version Control","text":"First, go GitHub page make new repository  Pick descriptive name repository. name R project created. can choose whether repository public private, don’t need mess additional options1. Go ahead create repository. taken screen information clone project. want copy URL listed use later:  Now create new R project. Select “Version Control” type project want create, select “git” type version control. Paste URL GitHub project, make sure project created folder want (’m creating “workspace” folder), click “Create Project.”  Now new R project! ’ll notice RStudio created new files. Let’s setup renv project commit new files push GitHub. first thing run renv::init() start using renv project:  Now navigate git tab upper right corner RStudio see list files. changes yet committed. want add files one commit, check boxes (aka “stage” files) click commit button.  new window pops lets us review committing. left-hand side, can click files committed see changed. right-hand side, add short message describes nature commit. first commit, ’s fine just write “initial commit.” Click “Commit” button right commit message, congratulations! just made first commit.  Remember commits just local. Now push GitHub sync website computer. Thankfully ’s simple clicking green arrow push. blue arrow pull.  pushed GitHub, now able refresh repository web browser see changes. can see recent commit message screenshot , also number commits made.  rest project, follow commit/push cycle just . Make changes, select changes git tab click commit button, make commit click push button. ’s !","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/zen/anatomy-4.html","id":"local-first","dir":"Articles > Zen","previous_headings":"Setup your project to use git/GitHub","what":"Local First","title":"Anatomy of an R Project: Version Control","text":"first thing create new project RStudio, using git renv:  new R project created, initial files need. Let’s commit “initial commit.” exact procedure initial commit GitHub First flow.   Now process commit R project, however don’t place push code since GitHub repository doesn’t exist yet. Go GitHub create new repository, name thing named R project. (don’t need , kind confusing otherwise!)  respository created, copy URL project GitHub first workflow. Now ’s need use command line little bit. need use command line git commands run slightly advanced something can using “point click” interface RStudio. first command need run git remote add origin <GitHub URL>. tells git adding new remote repository push . name remote origin convention. second command run git push --set-upstream. RStudio doesn’t quite enough information push code , first push needs extra information (--set-upstream). technical detail branches, etc. two commands look like :  , can resume normal cycle pushing code clicking green arrow RStudio git panel.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/zen/anatomy-4.html","id":"comparisons","dir":"Articles > Zen","previous_headings":"Setup your project to use git/GitHub","what":"Comparisons","title":"Anatomy of an R Project: Version Control","text":"differences local-first GitHub-first approaches creating projects fairly small, scheme things. create project GitHub first, manually setup renv. create project locally first, manually configure GitHub repository ’re pushing . get past minor differences, process exact : Choose files commit clicking checkbox next file names RStudio’s git panel Click Commit button add message describing ’ve changed commit Click green arrow push commit GitHub","code":""},{"path":"https://nateybear.github.io/metrics-in-r/articles/zen/anatomy-4.html","id":"conclusions","dir":"Articles > Zen","previous_headings":"","what":"Conclusions","title":"Anatomy of an R Project: Version Control","text":"article may seem little complicated, remember two things: learning curve using git. need least familiar terminology can understand buttons RStudio mean. time, learning curve isn’t big might seem. ’re comfortable language around committing, pushing, pulling, good go. article configuration. Configuration hard part. get setup git using day--day, ’s practically mindless. Day--day use simple three bullet points listed . can quickly venture complex territory git, can also stay surface level done article live happy, stress-free life programmer. may ask, “use git complicated?” answer inertia massive force computer programming. Even superior alternative git existed, take many years lot concerted effort part many people make standard. now, everyone uses git . Just stay weeds can maintain zenlike approach programming. get weeds, find someone knows git help . Happy Coding!","code":""},{"path":"https://nateybear.github.io/metrics-in-r/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Nathan Gardner Hattersley. Author, maintainer.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Gardner Hattersley N (2023). metrics..r: Econometrics Homework R. https://github.com/nateybear/metrics--r, https://nateybear.github.io/metrics--r/.","code":"@Manual{,   title = {metrics.in.r: Do Your Econometrics Homework in R},   author = {Nathan {Gardner Hattersley}},   year = {2023},   note = {https://github.com/nateybear/metrics-in-r, https://nateybear.github.io/metrics-in-r/}, }"},{"path":"https://nateybear.github.io/metrics-in-r/index.html","id":"welcome","dir":"","previous_headings":"","what":"Do Your Econometrics Homework in R","title":"Do Your Econometrics Homework in R","text":"website meant resource Econometrics students learning R. R package series articles explain use R statistics zen-like way. intended complement two books: Introduction Econometrics R Christoph Hanck, Martin Arnold, Alexander Gerber, Martin Schmelzer; R Data Science Hadley Wickham Garrett Grolemund. Introduction Econometrics R follows Jeffery Wooldridge’s textbook name shows implement selected applications. intro econometrics classes cover portions Wooldridge sometimes stray quite far material. Hence, website tries concise complement Introduction Econometrics R, offering practical tools different things seen covered metrics courses.  R Data Science broad overview R tidyverse (collection packages within R). starts slow beginner level eventually covers vast array important concepts. ’s highly recommended (perhaps required) reading new R programmers. website partly assumes background information contained R Data Science builds specific recommendations econometrics academic research.","code":""},{"path":[]},{"path":"https://nateybear.github.io/metrics-in-r/index.html","id":"id_1-metapackage","dir":"","previous_headings":"Purpose of the Package","what":"1. Metapackage","title":"Do Your Econometrics Homework in R","text":"metapackage package contains packages. install package, also install curated list packages created. feel fastest way get “set ” complete environment can econometrics R.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/index.html","id":"id_2-documentation","dir":"","previous_headings":"Purpose of the Package","what":"2. Documentation","title":"Do Your Econometrics Homework in R","text":"series articles website created TA review sessions covered important aspects programming R. two sections: Art Metrics contains articles basic estimation inference techniques advanced undergraduate first-semester graduate econometrics class. focuses heavily comparisons Stata aims build foundational set metrics tools. Zen Programming completely different focus previous section. budding computer scientists (.k.. ) sometimes miss whole world non-technical skills make programming productive, fun, reproducible. dubbed “Hidden Curriculum” data science Scott Cunningham. Zen Programming aims take “hidden” title teach set skills project management help produce high-quality, shareable, understandable academic research.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/index.html","id":"id_3-code","dir":"","previous_headings":"Purpose of the Package","what":"3. Code","title":"Do Your Econometrics Homework in R","text":"things complicated program, cases try write functions use. ’re free use econometrics homeworks, understanding assume liability function gives incorrect answers. thoroughly test validate functions write, don’t desire time spend tinkering incessantly. eventually figure . employer won’t like loading grad student’s GitHub repo million-dollar software project, eventually know implement function. sounds dandy , head Get Started page installation instructions, start reading articles!","code":""},{"path":"https://nateybear.github.io/metrics-in-r/reference/lincom.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Linear Functions of Model Parameters — lincom","title":"Estimate Linear Functions of Model Parameters — lincom","text":"Given model returned function lm() one expressions evaluate, construct point estimate confidence intervals expression(s) using exact delta method. Estimate p-values using t distribution exact finite-sample distribution.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/reference/lincom.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Linear Functions of Model Parameters — lincom","text":"","code":"lincom(model, ..., vcov. = NULL, params = NULL)"},{"path":"https://nateybear.github.io/metrics-in-r/reference/lincom.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Linear Functions of Model Parameters — lincom","text":"model linear model, fit call lm, feols, lm_robust ... One expressions involving parameters model vcov. Optional specify covariance model. Can matrix, function lambda. Defaults stats::vcov(model) params Optional character vector. rename model parameters make easier refer expressions ...","code":""},{"path":"https://nateybear.github.io/metrics-in-r/reference/lincom.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate Linear Functions of Model Parameters — lincom","text":"two ways refer model parameters expressions. names model coefficients, educ abil. Note \"strange\" expressions evaluate symbol R code must surrounded backticks, e.g. `(Intercept)` `educ:abil`. Using names supplied params argument function. order coefficients order returned coef(model). default, covariances model parameters taken stats::vcov() function. generic function produce different results different model types. means lm() models homoskedastic covariance matrix, whereas feols lm_robust models type robust covariance matrix specify creating model. can override default behavior using vcov. argument.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/reference/lincom.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Linear Functions of Model Parameters — lincom","text":"","code":"library(fixest) model <- feols(mpg ~ wt + hp, data = mtcars, vcov = \"HC1\")  lincom(model, wt + 3, 2 * hp) #> # A tibble: 2 × 7 #>   Expression Estimate `Std. Error` `t-Value` `Pr(>|t|)` `CI Lower` `CI Upper` #>   <chr>         <dbl>        <dbl>     <dbl>      <dbl>      <dbl>      <dbl> #> 1 wt + 3      -0.878        0.651      -1.35  0.188         0.454     -2.21   #> 2 2 * hp      -0.0635       0.0140     -4.55  0.0000882    -0.0350    -0.0921  # equivalently, supply your own parameter names library(glue) lincom(model, b2 + 3, 2 * b3, params = glue(\"b{1:3}\")) #> # A tibble: 2 × 7 #>   Expression Estimate `Std. Error` `t-Value` `Pr(>|t|)` `CI Lower` `CI Upper` #>   <chr>         <dbl>        <dbl>     <dbl>      <dbl>      <dbl>      <dbl> #> 1 b2 + 3      -0.878        0.651      -1.35  0.188         0.454     -2.21   #> 2 2 * b3      -0.0635       0.0140     -4.55  0.0000882    -0.0350    -0.0921 #>  #> ℹ Where b1=(Intercept), b2=wt, b3=hp"},{"path":"https://nateybear.github.io/metrics-in-r/reference/nlcom.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Non-Linear Functions of Model Parameters — nlcom","title":"Estimate Non-Linear Functions of Model Parameters — nlcom","text":"Given model returned function lm() one expressions evaluate, construct point estimate confidence intervals expression(s) using delta method. Estimate p-values using normal distribution asymptotic approximation.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/reference/nlcom.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Non-Linear Functions of Model Parameters — nlcom","text":"","code":"nlcom(model, ..., vcov. = NULL, params = NULL)"},{"path":"https://nateybear.github.io/metrics-in-r/reference/nlcom.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Non-Linear Functions of Model Parameters — nlcom","text":"model linear model, fit call lm, feols, lm_robust ... One expressions involving parameters model vcov. Optional specify covariance model. Can matrix, function lambda. Defaults stats::vcov(model) params Optional character vector. rename model parameters make easier refer expressions ...","code":""},{"path":"https://nateybear.github.io/metrics-in-r/reference/nlcom.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Non-Linear Functions of Model Parameters — nlcom","text":"list containing results running delta method, along specialized print method print summary table p-values","code":""},{"path":"https://nateybear.github.io/metrics-in-r/reference/nlcom.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate Non-Linear Functions of Model Parameters — nlcom","text":"two ways refer model parameters expressions. names model coefficients, educ abil. Note \"strange\" expressions evaluate symbol R code must surrounded backticks, e.g. `(Intercept)` `educ:abil`. Using names supplied params argument function. order coefficients order returned coef(model). default, covariances model parameters taken stats::vcov() function. generic function produce different results different model types. means lm() models homoskedastic covariance matrix, whereas feols lm_robust models type robust covariance matrix specify creating model. can override default behavior using vcov. argument.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/reference/nlcom.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Non-Linear Functions of Model Parameters — nlcom","text":"","code":"library(fixest) model <- feols(mpg ~ wt + hp, data = mtcars, vcov = \"HC1\")  nlcom(model, wt^2, sqrt(hp / wt)) #> # A tibble: 2 × 7 #>   Expression    Estimate `Std. Error` `Z-Value` `Pr(>|z|)` `CI Lower` `CI Upper` #>   <chr>            <dbl>        <dbl>     <dbl>      <dbl>      <dbl>      <dbl> #> 1 wt^2           15.0          5.05        2.98   2.91e- 3     25.4       4.71   #> 2 sqrt(hp / wt)   0.0905       0.0147      6.14   8.13e-10      0.121     0.0604  # equivalently, supply your own parameter names library(glue) nlcom(model, b2^2, sqrt(b3 / b2), params = glue(\"b{1:3}\")) #> # A tibble: 2 × 7 #>   Expression    Estimate `Std. Error` `Z-Value` `Pr(>|z|)` `CI Lower` `CI Upper` #>   <chr>            <dbl>        <dbl>     <dbl>      <dbl>      <dbl>      <dbl> #> 1 b2^2           15.0          5.05        2.98   2.91e- 3     25.4       4.71   #> 2 sqrt(b3 / b2)   0.0905       0.0147      6.14   8.13e-10      0.121     0.0604 #>  #> ℹ Where b1=(Intercept), b2=wt, b3=hp"},{"path":"https://nateybear.github.io/metrics-in-r/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://nateybear.github.io/metrics-in-r/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://nateybear.github.io/metrics-in-r/reference/test.html","id":null,"dir":"Reference","previous_headings":"","what":"Jointly Test Linear Functions of Model Parameters — test","title":"Jointly Test Linear Functions of Model Parameters — test","text":"Given model returned function lm() one expressions evaluate, jointly test null hypothesis expression zero, using exact delta method construct F statistic. finite-sample Wald test.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/reference/test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Jointly Test Linear Functions of Model Parameters — test","text":"","code":"test(model, ..., vcov. = NULL, params = NULL)"},{"path":"https://nateybear.github.io/metrics-in-r/reference/test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Jointly Test Linear Functions of Model Parameters — test","text":"model linear model, fit call lm, feols, lm_robust ... One expressions involving parameters model vcov. Optional specify covariance model. Can matrix, function lambda. Defaults stats::vcov(model) params Optional character vector. rename model parameters make easier refer expressions ...","code":""},{"path":"https://nateybear.github.io/metrics-in-r/reference/test.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Jointly Test Linear Functions of Model Parameters — test","text":"two ways refer model parameters expressions. names model coefficients, educ abil. Note \"strange\" expressions evaluate symbol R code must surrounded backticks, e.g. `(Intercept)` `educ:abil`. Using names supplied params argument function. order coefficients order returned coef(model). default, covariances model parameters taken stats::vcov() function. generic function produce different results different model types. means lm() models homoskedastic covariance matrix, whereas feols lm_robust models type robust covariance matrix specify creating model. can override default behavior using vcov. argument.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/reference/test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Jointly Test Linear Functions of Model Parameters — test","text":"","code":"library(fixest) model <- feols(mpg ~ wt + hp, data = mtcars, vcov = \"HC1\")  test(model, wt + 3, 2 * hp) #> Error in summaryTable.test(x): object 'model' not found  # equivalently, supply your own parameter names library(glue) test(model, wt + 3, 2 * hp, params = glue(\"b{1:3}\")) #> Error in purrr::map_dbl(exprs, quo_eval): ℹ In index: 1. #> Caused by error: #> ! object 'wt' not found"},{"path":"https://nateybear.github.io/metrics-in-r/reference/testnl.html","id":null,"dir":"Reference","previous_headings":"","what":"Jointly Test Non-Linear Functions of Model Parameters — testnl","title":"Jointly Test Non-Linear Functions of Model Parameters — testnl","text":"Given model returned function lm() one expressions evaluate, jointly test null hypothesis expression zero, using approximate delta method construct chi-square statistic. asymptotic Wald test.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/reference/testnl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Jointly Test Non-Linear Functions of Model Parameters — testnl","text":"","code":"testnl(model, ..., vcov. = NULL, params = NULL)"},{"path":"https://nateybear.github.io/metrics-in-r/reference/testnl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Jointly Test Non-Linear Functions of Model Parameters — testnl","text":"model linear model, fit call lm, feols, lm_robust ... One expressions involving parameters model vcov. Optional specify covariance model. Can matrix, function lambda. Defaults stats::vcov(model) params Optional character vector. rename model parameters make easier refer expressions ...","code":""},{"path":"https://nateybear.github.io/metrics-in-r/reference/testnl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Jointly Test Non-Linear Functions of Model Parameters — testnl","text":"two ways refer model parameters expressions. names model coefficients, educ abil. Note \"strange\" expressions evaluate symbol R code must surrounded backticks, e.g. `(Intercept)` `educ:abil`. Using names supplied params argument function. order coefficients order returned coef(model). default, covariances model parameters taken stats::vcov() function. generic function produce different results different model types. means lm() models homoskedastic covariance matrix, whereas feols lm_robust models type robust covariance matrix specify creating model. can override default behavior using vcov. argument.","code":""},{"path":"https://nateybear.github.io/metrics-in-r/reference/testnl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Jointly Test Non-Linear Functions of Model Parameters — testnl","text":"","code":"library(fixest) model <- feols(mpg ~ wt + hp, data = mtcars, vcov = \"HC1\")  testnl(model, wt^2, sqrt(hp / wt)) #> Joint Chi-Square Test of the hypotheses #> • wt^2 = 0 #> • sqrt(hp / wt) = 0 #>                chisq(2) = 197.004154               #>                   Pr(>chisq) = 0                    # equivalently, supply your own parameter names library(glue) testnl(model, b2^2, sqrt(b3 / b2), params = glue(\"b{1:3}\")) #> Joint Chi-Square Test of the hypotheses #> • b2^2 = 0 #> • sqrt(b3 / b2) = 0 #>                chisq(2) = 197.004154               #>                   Pr(>chisq) = 0                   #>  #> ℹ Where b1=(Intercept), b2=wt, b3=hp"}]
